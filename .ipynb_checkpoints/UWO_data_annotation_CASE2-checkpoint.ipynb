{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation tool for time series data\n",
    "\n",
    "By: Stefania Russo, Kris Villez\n",
    "Copyright: 2018, distributed with BSD3 license "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The challenge\n",
    "\n",
    "In the context of the ADASen project, we want to address research questions regarding the utility of supervised and unsupervised machine learning models in anomaly detection for environmental systems. We have therefore selected a range of anomaly detection methods for benchmarking on data sets produced by six infrastructures at Eawag.\n",
    "\n",
    "Critical to the benchmarking is the availability of fully labelled training and test data sets of normal and abnormal behavior in environmental data. \n",
    "An annotation tool has therefore being developed to perform the labelling procedure.\n",
    "\n",
    "This notebook shows an application of the labelling procedure to time series data. Here, each time series is a univariate 24h signal from a spatially-distributed, low-power sensor network.\n",
    "\n",
    "Each series is visualised as a 3am-3am time series.\n",
    "\n",
    "## Current method\n",
    "\n",
    "Below are described the steps for data access, data preparation, visualization and labelling procedure.\n",
    "\n",
    "- The data is in the form of .csv data files. Each data file consists of many 24h sets across 3 sensors.\n",
    "- Corruption checks are performed and dates cointaining corrupted time-series are removed\n",
    "- The labelling procedure starts and the first plots are displayed. The 3 plots at the top are univariate sensor signals, where the bottom plot shows a collection of these signals.  \n",
    "\n",
    "- The annotation tool allows the labelling expert to interactivelly select multiple portions of the time series by moving through the data with the mouse cursor.\n",
    "\n",
    "- Each time the button 'Next' is clicked, all the selected areas (time index and sensor value) are saved together with information about the date stamp date. At the end of the procedure, the user can easily access to the anomaly labels in an easy manner.\n",
    "\n",
    "- When the process is over, the plots need to be closed and then the cell 'Save labelled data' hs to be run \n",
    "\n",
    "- Note: if the user wants to change any of his selections, he needs to move forward to the next plot by clicking 'Next', perform a selection of the anomalous data, and then go back and restart.\n",
    "\n",
    "\n",
    "# Usage\n",
    "\n",
    " - Install python and open this Jupyter notebook \n",
    " - Paste your working directory into path_all\n",
    " \n",
    "# NOTE: \n",
    "## This is a beta version of the labelling tool! Please provide any feedback\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iniziatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.widgets import Button\n",
    "from matplotlib.widgets import SpanSelector\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import datetime as datetime\n",
    "\n",
    "# WINDOWS server: KV can find the data here\n",
    "# path_all = ('//eaw-dc02/ea-daten/Abteilungsprojekte/eng/SWWData/2018_datValX/4_workspace/R/')\n",
    "\n",
    "# iOS server: SR can find the data here\n",
    "# path_all = (\"/Volumes/UWO/\")\n",
    "\n",
    "# On SR's laptop\n",
    "path_all = ('/Users/russoste/Desktop/Z_UWO/Data/')\n",
    "\n",
    "name_of_file1 = '181128_trialData_UWOforADASen_case1.csv'\n",
    "name_of_file2 = '181128_trialData_UWOforADASen_case2.csv'\n",
    "\n",
    "save_path = path_all     # Destination folder to for saving text file\n",
    "name_of_file_l1 = \"Labels_Case2_\"\n",
    "name_of_file_l1_time = \"Labels_Case2_time_\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and basic sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor names: bf_07 , bl_ceb60 , bf_08\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "completePath = os.path.join(path_all, name_of_file2) \n",
    "df = pd.read_csv(completePath)\n",
    "\n",
    "\n",
    "df2 = df.copy(deep=True)\n",
    "df2['date'], df2['time'] = df2['time'].str.split(' ', 1).str\n",
    "\n",
    "sr0 = df2.keys()[1]\n",
    "sr1 = df2.keys()[2]\n",
    "sr2 = df2.keys()[3]\n",
    "print('Sensor names:',sr0,',', sr1,',', sr2)\n",
    "\n",
    "# Replace extreme values with zeros and create datetime\n",
    "# Replace extreme values with zeros and create datetime\n",
    "\n",
    "df2[sr0] = df2[sr0].replace([-9999.000], 0)\n",
    "df2[sr1] = df2[sr1].replace([-9999.000], 0)\n",
    "df2[sr2] = df2[sr2].replace([-9999.000], 0)\n",
    "df2['date'] = [x.date() for x in (pd.to_datetime([i for i in df2['date']], format='%Y-%m-%d'))] \n",
    "df2['time'] = [x.time() for x in (pd.to_datetime([i for i in df2['time']], format='%H:%M:%S'))]   # remove primes from the time\n",
    "df1 = df2.copy(deep=True)\n",
    "df2.set_index(['date','time'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique dates: DatetimeIndex(['2018-09-01', '2018-09-02', '2018-09-03', '2018-09-04',\n",
      "               '2018-09-05', '2018-09-06', '2018-09-07', '2018-09-08',\n",
      "               '2018-09-09', '2018-09-10', '2018-09-11', '2018-09-12',\n",
      "               '2018-09-13', '2018-09-14', '2018-09-15', '2018-09-16',\n",
      "               '2018-09-17', '2018-09-18', '2018-09-19', '2018-09-20',\n",
      "               '2018-09-21', '2018-09-22', '2018-09-23', '2018-09-24',\n",
      "               '2018-09-25', '2018-09-26', '2018-09-27', '2018-09-28',\n",
      "               '2018-09-29', '2018-09-30', '2018-10-01', '2018-10-02',\n",
      "               '2018-10-03', '2018-10-04', '2018-10-05', '2018-10-06',\n",
      "               '2018-10-07', '2018-10-08', '2018-10-09', '2018-10-10',\n",
      "               '2018-10-11', '2018-10-12', '2018-10-13', '2018-10-14',\n",
      "               '2018-10-15', '2018-10-16', '2018-10-17', '2018-10-18',\n",
      "               '2018-10-19', '2018-10-20', '2018-10-21', '2018-10-22',\n",
      "               '2018-10-23', '2018-10-24', '2018-10-25', '2018-10-26',\n",
      "               '2018-10-27', '2018-10-28', '2018-10-29', '2018-10-30',\n",
      "               '2018-10-31', '2018-11-01', '2018-11-02', '2018-11-03',\n",
      "               '2018-11-04', '2018-11-05', '2018-11-06', '2018-11-07',\n",
      "               '2018-11-08', '2018-11-09', '2018-11-10', '2018-11-11',\n",
      "               '2018-11-12'],\n",
      "              dtype='datetime64[ns]', name='date', freq=None)\n",
      "Corrupted date: 2018-10-16\n",
      "Corrupted date index: 12960\n",
      "Corrupted date shape: (290, 3)\n",
      "Corrupted date: 2018-11-12\n",
      "Corrupted date index: 20738\n",
      "Corrupted date shape: (243, 3)\n"
     ]
    }
   ],
   "source": [
    "# Accessing dates\n",
    "i_date = df2.index.get_level_values(0)          # get all dates\n",
    "idx_date = np.unique(df2.index.get_level_values(0), return_index=True)[1]      # get index of unique dates\n",
    "date_list = i_date[idx_date]   # get list of all dates\n",
    "print('Unique dates:',date_list)\n",
    "\n",
    "df_bf_00 = df2[sr0]\n",
    "df_bf_01 = df2[sr1]\n",
    "df_bf_02 = df2[sr2]\n",
    "\n",
    "for pl_i in range(len(date_list)):\n",
    "    if len(df_bf_00[date_list[pl_i].date()].values) != 288:\n",
    "        print('Corrupted date:', date_list[pl_i].date())\n",
    "        print('Corrupted date index:',idx_date[pl_i])\n",
    "        print('Corrupted date shape:', df2.loc[date_list[pl_i].date()].shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(index='2018-10-16', level=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove corrupted dataframe and compute new date list\n",
    "data_df = df2[:-243]\n",
    "\n",
    "# Accessing dates\n",
    "i_date = data_df.index.get_level_values(0)          # get all dates\n",
    "idx_date = np.unique(data_df.index.get_level_values(0), return_index=True)[1]      # get index of unique dates\n",
    "date_list = i_date[idx_date]   # get list of all dates\n",
    "#print('Unique dates',date_list)\n",
    "\n",
    "# Dates and times\n",
    "data_time = []\n",
    "for pl_i in idx_date:                             # create data_time indeces to have access later\n",
    "    time = data_df.loc[i_date[pl_i]].index\n",
    "    data_time.append(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 3am-3am data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 70.0\n"
     ]
    }
   ],
   "source": [
    "# Data points from 00:00:00 till 02:55:00\n",
    "tmp0 = data_df[sr0]\n",
    "tmp1 = tmp0[date_list[0].date()].loc[datetime.time(0,0,0):datetime.time(2,55,0)]\n",
    "tmp2 = tmp0[date_list[0].date()].loc[datetime.time(3,0,0):datetime.time(23,55,0)]\n",
    "#print(len(tmp1), len(tmp2))\n",
    "\n",
    "X = data_df.values\n",
    "X = X[len(tmp1) : -len(tmp2)]     # this is my new data set\n",
    "\n",
    "tmp3 = time[len(tmp1):]\n",
    "tmp4 = time[:len(tmp1)]\n",
    "time_s = np.concatenate((tmp3,tmp4))\n",
    "\n",
    "tmp3 = data_time[0][len(tmp1):]\n",
    "tmp4 = data_time[0][:len(tmp1)]\n",
    "time_s1 = np.concatenate((tmp3,tmp4))\n",
    "\n",
    "\n",
    "### Create individual lists of data\n",
    "\n",
    "nc = X.shape[0]/288\n",
    "print('Number of examples:', nc)\n",
    "\n",
    "data_sr0 = X[:,0]\n",
    "data_sr1 = X[:,1]\n",
    "data_sr2 = X[:,2]\n",
    "\n",
    "data_sr0 = np.array(np.split(data_sr0,nc))      # Divide data in shape for plotting\n",
    "data_sr1 = np.array(np.split(data_sr1,nc))\n",
    "data_sr2 = np.array(np.split(data_sr2,nc))\n",
    "\n",
    "date_list_n = len(data_sr0)  # I have lost part of the data (last day)\n",
    "dates = date_list[0:len(data_sr0)]\n",
    "\n",
    "time_int = []\n",
    "for ind in range(X.shape[0]):\n",
    "    time = np.linspace(00.0, 23.55, num=len(data_sr0[0]))\n",
    "    time_int.append(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "\n",
    "data1 = []\n",
    "data2 = []\n",
    "data3 = []\n",
    "data123 = []\n",
    "\n",
    "itera = dates\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "gs = gridspec.GridSpec(2, 3)\n",
    "\n",
    "fig = plt.figure()\n",
    "#plt.axis([0, 24, -3, 100])\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0]) # row 0, col 0\n",
    "ax2 = fig.add_subplot(gs[0, 1]) # row 0, col 1\n",
    "ax3 = fig.add_subplot(gs[0, 2]) # row 0, col 1\n",
    "ax4 = fig.add_subplot(gs[1, :]) # row 1, span all columns\n",
    "\n",
    "ax1.set_title('bf_07', fontdict=None, pad=None)\n",
    "ax2.set_title('bl_ceb60', fontdict=None, pad=None)\n",
    "ax3.set_title('bf_08', fontdict=None, pad=None)\n",
    "ax4.set_title('bf_07 + bl_ceb60 + bf_08', fontdict=None, pad=None)\n",
    "\n",
    "fig.suptitle(str(dates[0].date()), fontsize=12)\n",
    "\n",
    "ax1.set_ylim([-3,100])\n",
    "ax2.set_ylim([-3,100])\n",
    "ax3.set_ylim([-3,100])\n",
    "ax4.set_ylim([-3,100])\n",
    "\n",
    "for pl_i in range(len(dates)): \n",
    "    ax1.plot(time_int[pl_i], data_sr0[pl_i], '#C0C0C0', lw=2)\n",
    "    ax2.plot(time_int[pl_i], data_sr1[pl_i], '#C0C0C0', lw=2)\n",
    "    ax3.plot(time_int[pl_i], data_sr2[pl_i],  '#C0C0C0',lw=2) \n",
    "    \n",
    "l, = ax1.plot(time_int[0], data_sr0[0], '#1E90FF', lw=2)     #the first one is the one in blue\n",
    "l2, = ax2.plot(time_int[0], data_sr1[0], '#8B008B')\n",
    "l3, = ax3.plot(time_int[0], data_sr2[0],'#FFDAB9')\n",
    "\n",
    "\n",
    "ll1, = ax4.plot(time_int[0], data_sr0[0], '#1E90FF')\n",
    "ll2, = ax4.plot(time_int[0], data_sr1[0], '#8B008B')\n",
    "ll3, = ax4.plot(time_int[0],  data_sr2[0], '#FFDAB9')\n",
    "\n",
    "\n",
    "############### Buttons widget  ####################\n",
    "\n",
    "class Index(object):\n",
    "    ind = 0\n",
    "\n",
    "    def next(self, event):\n",
    "        self.ind += 1\n",
    "        i = self.ind % len(itera)\n",
    "\n",
    "        #ydata0 will be the plot alone\n",
    "        ydata1 = data_sr0[i]   \n",
    "        ydata2 = data_sr1[i] \n",
    "        ydata3 = data_sr2[i]\n",
    "        xdata = time_int[i]          \n",
    "        \n",
    "        l.set_ydata(ydata1)\n",
    "        l.set_xdata(xdata)\n",
    "        l2.set_ydata(ydata2)\n",
    "        l2.set_xdata(xdata)\n",
    "        l3.set_ydata(ydata3)\n",
    "        l3.set_xdata(xdata)\n",
    "        \n",
    "        ll1.set_ydata(ydata1)\n",
    "        ll2.set_ydata(ydata2)\n",
    "        ll3.set_ydata(ydata3) \n",
    "        \n",
    "        ll1.set_xdata(xdata) \n",
    "        ll2.set_xdata(xdata)\n",
    "        ll3.set_xdata(xdata)\n",
    "        \n",
    "        if (i == (0)):\n",
    "            fig.suptitle('End of data files - restarting with data file ' + str(dates[i].date()), fontsize=12)\n",
    "        else: \n",
    "            fig.suptitle(str(dates[i].date()), fontsize=12)\n",
    "            \n",
    "        plt.draw()\n",
    "\n",
    "    def prev(self, event):\n",
    "        self.ind -= 1\n",
    "        i = self.ind % len(itera)\n",
    "        \n",
    "        #ydata0 will be the plot alone\n",
    "        ydata1 = data_sr0[i]   \n",
    "        ydata2 = data_sr1[i] \n",
    "        ydata3 = data_sr2[i]\n",
    "        xdata = time_int[i]          \n",
    "        \n",
    "        l.set_ydata(ydata1)\n",
    "        l.set_xdata(xdata)\n",
    "        \n",
    "        l2.set_ydata(ydata2)\n",
    "        l2.set_xdata(xdata)\n",
    "        \n",
    "        l3.set_ydata(ydata3)\n",
    "        l3.set_xdata(xdata)\n",
    "\n",
    "        ll1.set_ydata(ydata1)\n",
    "        ll2.set_ydata(ydata2)\n",
    "        ll3.set_ydata(ydata3) \n",
    "\n",
    "        ll1.set_xdata(xdata) \n",
    "        ll2.set_xdata(xdata)\n",
    "        ll3.set_xdata(xdata)\n",
    "        \n",
    "        if (i == (0)):\n",
    "            fig.suptitle('End of data files - restarting with data file ' + str(dates[i].date()), fontsize=12)\n",
    "        else: \n",
    "            fig.suptitle(str(dates[i].date()), fontsize=12)        \n",
    "        \n",
    "        plt.draw()\n",
    "\n",
    "callback = Index()\n",
    "\n",
    "axprev = plt.axes([0.7, 0.05, 0.1, 0.075])\n",
    "axnext = plt.axes([0.81, 0.05, 0.1, 0.075])\n",
    "bnext = Button(axnext, 'Next')\n",
    "bnext.on_clicked(callback.next)\n",
    "\n",
    "bprev = Button(axprev, 'Previous')\n",
    "bprev.on_clicked(callback.prev)\n",
    "\n",
    "\"\"\"\n",
    "valore = '11'\n",
    "def presskey(event):\n",
    "    print('Pressed key = ', event.key)\n",
    "    #sys.stdout.flush()    \n",
    "    global valore \n",
    "    valore = event.key       \n",
    "    return valore\n",
    "\"\"\"\n",
    "\n",
    "def onselect1(xmin, xmax):\n",
    "    x = time_int[callback.ind % len(itera)]\n",
    "    y = data_sr0[callback.ind % len(itera)]\n",
    "    today = dates[callback.ind % len(itera)]\n",
    "   \n",
    "    indmin1, indmax1 = np.searchsorted(x, (xmin, xmax))\n",
    "    indmax1 = min(len(x) - 1, indmax1)\n",
    "    thisx = x[indmin1:indmax1]\n",
    "    thisy = y[indmin1:indmax1]    \n",
    "    nplist = np.array([today.date() for i in range(len(thisx))])\n",
    "        \n",
    "    a1 = np.c_[nplist, thisx, thisy]\n",
    "    global data1\n",
    "    data1.extend(a1)\n",
    "    #np.savetxt(completeName_label_1, data1)\n",
    "\n",
    "        \n",
    "\n",
    "def onselect2(xmin, xmax):\n",
    "    x = time_int[callback.ind % len(itera)]\n",
    "    y = data_sr1[callback.ind % len(itera)]\n",
    "    today = dates[callback.ind % len(itera)]\n",
    "    \n",
    "    indmin, indmax = np.searchsorted(x, (xmin, xmax))\n",
    "    indmax = min(len(x) - 1, indmax)\n",
    "    thisx = x[indmin:indmax]\n",
    "    thisy = y[indmin:indmax]\n",
    "    nplist = np.array([today.date() for i in range(len(thisx))])\n",
    "    \n",
    "    a2 = np.c_[nplist, thisx, thisy]\n",
    "    global data2\n",
    "    data2.extend(a2)\n",
    "    \n",
    "\n",
    "def onselect3(xmin, xmax):\n",
    "    x = time_int[callback.ind % len(itera)]\n",
    "    y = data_sr2[callback.ind % len(itera)]\n",
    "    today = dates[callback.ind % len(itera)]\n",
    "    \n",
    "    indmin, indmax = np.searchsorted(x, (xmin, xmax))\n",
    "    indmax = min(len(x) - 1, indmax)\n",
    "    thisx = x[indmin:indmax]\n",
    "    thisy = y[indmin:indmax]\n",
    "    nplist = np.array([today.date() for i in range(len(thisx))])\n",
    "    \n",
    "    a3 = np.c_[nplist, thisx, thisy]\n",
    "    global data3\n",
    "    data3.extend(a3)\n",
    "\n",
    "def onselect4(xmin, xmax):\n",
    "    x = time_int[callback.ind % len(itera)]\n",
    "    y1 = data_sr0[callback.ind % len(itera)]\n",
    "    y2 = data_sr1[callback.ind % len(itera)]\n",
    "    y3 = data_sr2[callback.ind % len(itera)]\n",
    "    today = dates[callback.ind % len(itera)]\n",
    "    \n",
    "    indmin, indmax = np.searchsorted(x, (xmin, xmax))\n",
    "    indmax = min(len(x) - 1, indmax)\n",
    "    \n",
    "    thisx = x[indmin:indmax]\n",
    "    thisy1 = y1[indmin:indmax]\n",
    "    thisy2 = y2[indmin:indmax]\n",
    "    thisy3 = y3[indmin:indmax] \n",
    "    nplist = np.array([today.date() for i in range(len(thisx))])\n",
    "        \n",
    "    # save\n",
    "    a123 = np.c_[nplist, thisx, thisy1, thisy2, thisy3]\n",
    "    global data123\n",
    "    data123.extend(a123)\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "# Connect key event to figure\n",
    "fig.canvas.mpl_connect('key_press_event',presskey)\n",
    "\"\"\"\n",
    "\n",
    "#class1 = Onselect_1()\n",
    "\n",
    "spans1 = SpanSelector(ax1, onselect1, 'horizontal', useblit=True,\n",
    "                      rectprops=dict(alpha=0.5, facecolor='red'), span_stays=True)\n",
    "span2 = SpanSelector(ax2, onselect2, 'horizontal', useblit=True,\n",
    "                    rectprops=dict(alpha=0.5, facecolor='red'), span_stays=True )\n",
    "span3 = SpanSelector(ax3, onselect3, 'horizontal', useblit=True,\n",
    "                    rectprops=dict(alpha=0.5, facecolor='red'), span_stays=True)\n",
    "span4 = SpanSelector(ax4, onselect4, 'horizontal', useblit=True,\n",
    "                    rectprops=dict(alpha=0.5, facecolor='red') , span_stays=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame(data1, columns=['date','time', 'value'])\n",
    "data2 = pd.DataFrame(data2, columns=['date','time', 'value'])\n",
    "data3 = pd.DataFrame(data3, columns=['date','time', 'value'])\n",
    "data123 = pd.DataFrame(data123, columns=['date','time', 'bf_07','bl_ceb60','bf_08'])\n",
    "\n",
    "data1.to_csv(os.path.join(save_path, name_of_file_l1+sr0 + \".csv\") )\n",
    "data2.to_csv(os.path.join(save_path, name_of_file_l1+sr1 + \".csv\") )\n",
    "data2.to_csv(os.path.join(save_path, name_of_file_l1+sr2 + \".csv\") )\n",
    "data123.to_csv(os.path.join(save_path, name_of_file_l1+sr0+sr1+sr2 + \".csv\") )\n",
    "\n",
    "# Index of Date and time for correspondece \n",
    "arrsy = [time_int[1], time_s1]\n",
    "dfy = np.array(arrsy)\n",
    "dfy = pd.DataFrame(data=dfy)  # 1st row as the column names\n",
    "\n",
    "# Go back to the real timestamp\n",
    "\n",
    "data1_l = data1.copy(deep=True)\n",
    "for i in range(len(data1_l)):\n",
    "    for j in range(dfy.shape[1]):\n",
    "        if data1_l['time'].iloc[i] == dfy[j].iloc[0]:\n",
    "            #data1['time'].iloc[i] = dfy[j].iloc[0]\n",
    "            data1_l.replace(to_replace=data1_l['time'].iloc[i], value = dfy[j].iloc[1], inplace=True)\n",
    "            \n",
    "data2_l = data2.copy(deep=True)\n",
    "for i in range(len(data2_l)):\n",
    "    for j in range(dfy.shape[1]):\n",
    "        if data2_l['time'].iloc[i] == dfy[j].iloc[0]:\n",
    "            #data1['time'].iloc[i] = dfy[j].iloc[0]\n",
    "            data2_l.replace(to_replace=data2_l['time'].iloc[i], value = dfy[j].iloc[1], inplace=True)\n",
    "\n",
    "data3_l = data3.copy(deep=True)\n",
    "for i in range(len(data3_l)):\n",
    "    for j in range(dfy.shape[1]):\n",
    "        if data3_l['time'].iloc[i] == dfy[j].iloc[0]:\n",
    "            #data1['time'].iloc[i] = dfy[j].iloc[0]\n",
    "            data3_l.replace(to_replace=data3_l['time'].iloc[i], value = dfy[j].iloc[1], inplace=True)\n",
    "            \n",
    "data123_l = data123.copy(deep=True)\n",
    "for i in range(len(data123_l)):\n",
    "    for j in range(dfy.shape[1]):\n",
    "        if data123_l['time'].iloc[i] == dfy[j].iloc[0]:\n",
    "            #data1['time'].iloc[i] = dfy[j].iloc[0]\n",
    "            data123_l.replace(to_replace=data123_l['time'].iloc[i], value = dfy[j].iloc[1], inplace=True)\n",
    "            \n",
    "data1_l.to_csv(os.path.join(save_path, name_of_file_l1_time+sr0 + \".csv\") )\n",
    "data2_l.to_csv(os.path.join(save_path, name_of_file_l1_time+sr1 + \".csv\") )\n",
    "data2_l.to_csv(os.path.join(save_path, name_of_file_l1_time+sr2 + \".csv\") )\n",
    "data123_l.to_csv(os.path.join(save_path, name_of_file_l1_time+sr0+sr1+sr2 + \".csv\") )            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
