{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iniziatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.widgets import Button\n",
    "from matplotlib.widgets import SpanSelector\n",
    "import itertools\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "\n",
    "import datetime as datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# WINDOWS server: KV can find the data here\n",
    "# path_all = ('//eaw-dc02/ea-daten/Abteilungsprojekte/eng/SWWData/2018_datValX/4_workspace/R/')\n",
    "\n",
    "# iOS server: SR can find the data here\n",
    "# path_all = (\"/Volumes/UWO/\")\n",
    "\n",
    "# On SR's laptop\n",
    "path_all = ('/Users/russoste/Desktop/Z_UWO/Data/')\n",
    "\n",
    "name_of_file1 = '181128_trialData_UWOforADASen_case1.csv'\n",
    "name_of_file2 = '181128_trialData_UWOforADASen_case2.csv'\n",
    "\n",
    "save_path = path_all     # Destination folder to for saving text file\n",
    "name_of_file_l1 = \"Labels_1\"\n",
    "name_of_file_l2 = \"Labels_2\"\n",
    "completeName_label_1 = os.path.join(save_path, name_of_file_l_1 + \".txt\") \n",
    "completeName_label_2 = os.path.join(save_path, name_of_file_l_2 + \".txt\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# To Do:\n",
    "\n",
    "* Case 2 has not been implemented with 3am-3am \n",
    "* I would like to recreate the multi-indexed dataframe after creating series 3am-3am. Dates are missing\n",
    "* Plot titles have changed but not the content - ask Andy for confirmation OK I NEED TO CHANGE THEM\n",
    "* Use idx to save/append anomalous data with its proper x-index and dateframe index number\n",
    "* Connect datetime values to linespace values used to plot - so save the data\n",
    "\n",
    "\n",
    "Only 100 and 73 cases are shown. SImulation data can be added but it is too perfect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data  - CASE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor names: bf_03 , bf_04 , bl_ce193\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "completePath = os.path.join(path_all, name_of_file1) \n",
    "df = pd.read_csv(completePath)\n",
    "\n",
    "\n",
    "df2 = df.copy(deep=True)\n",
    "df2['date'], df2['time'] = df2['time'].str.split(' ', 1).str\n",
    "\n",
    "sr0 = df2.keys()[1]\n",
    "sr1 = df2.keys()[2]\n",
    "sr2 = df2.keys()[3]\n",
    "print('Sensor names:',sr0,',', sr1,',', sr2)\n",
    "\n",
    "# Replace extreme values with zeros and create datetime\n",
    "# Replace extreme values with zeros and create datetime\n",
    "\n",
    "df2[sr0] = df2[sr0].replace([-9999.000], 0)\n",
    "df2[sr1] = df2[sr1].replace([-9999.000], 0)\n",
    "df2[sr2] = df2[sr2].replace([-9999.000], 0)\n",
    "df2['date'] = [x.date() for x in (pd.to_datetime([i for i in df2['date']], format='%Y-%m-%d'))] \n",
    "df2['time'] = [x.time() for x in (pd.to_datetime([i for i in df2['time']], format='%H:%M:%S'))]   # remove primes from the time\n",
    "df1 = df2.copy(deep=True)\n",
    "df2.set_index(['date','time'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique dates: DatetimeIndex(['2018-03-06', '2018-03-07', '2018-03-08', '2018-03-09',\n",
      "               '2018-03-10', '2018-03-11', '2018-03-12', '2018-03-13',\n",
      "               '2018-03-14', '2018-03-15', '2018-03-16', '2018-03-17',\n",
      "               '2018-03-18', '2018-03-19', '2018-03-20', '2018-03-21',\n",
      "               '2018-03-22', '2018-03-23', '2018-03-24', '2018-03-25',\n",
      "               '2018-03-26', '2018-03-27', '2018-03-28', '2018-03-29',\n",
      "               '2018-03-30', '2018-03-31', '2018-04-01', '2018-04-02',\n",
      "               '2018-04-03', '2018-04-04', '2018-04-05', '2018-04-06',\n",
      "               '2018-04-07', '2018-04-08', '2018-04-09', '2018-04-10',\n",
      "               '2018-04-11', '2018-04-12', '2018-04-13', '2018-04-14',\n",
      "               '2018-04-15', '2018-04-16', '2018-04-17', '2018-04-18',\n",
      "               '2018-04-19', '2018-04-20', '2018-04-21', '2018-04-22',\n",
      "               '2018-04-23', '2018-04-24', '2018-04-25'],\n",
      "              dtype='datetime64[ns]', name='date', freq=None)\n"
     ]
    }
   ],
   "source": [
    "# Accessing dates\n",
    "i_date = df2.index.get_level_values(0)          # get all dates\n",
    "idx_date = np.unique(df2.index.get_level_values(0), return_index=True)[1]      # get index of unique dates\n",
    "date_list = i_date[idx_date]   # get list of all dates\n",
    "print('Unique dates:',date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrupted date: 2018-04-25\n",
      "Corrupted date index: 14400\n",
      "Corrupted date shape: (145, 3)\n"
     ]
    }
   ],
   "source": [
    "df_bf_00 = df2[sr0]\n",
    "df_bf_01 = df2[sr1]\n",
    "df_bf_02 = df2[sr2]\n",
    "\n",
    "for pl_i in range(len(date_list)):\n",
    "    if len(df_bf_00[date_list[pl_i].date()].values) != 288:\n",
    "        print('Corrupted date:', date_list[pl_i].date())\n",
    "        print('Corrupted date index:',idx_date[pl_i])\n",
    "        print('Corrupted date shape:', df2.loc[date_list[pl_i].date()].shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique dates DatetimeIndex(['2018-03-06', '2018-03-07', '2018-03-08', '2018-03-09',\n",
      "               '2018-03-10', '2018-03-11', '2018-03-12', '2018-03-13',\n",
      "               '2018-03-14', '2018-03-15', '2018-03-16', '2018-03-17',\n",
      "               '2018-03-18', '2018-03-19', '2018-03-20', '2018-03-21',\n",
      "               '2018-03-22', '2018-03-23', '2018-03-24', '2018-03-25',\n",
      "               '2018-03-26', '2018-03-27', '2018-03-28', '2018-03-29',\n",
      "               '2018-03-30', '2018-03-31', '2018-04-01', '2018-04-02',\n",
      "               '2018-04-03', '2018-04-04', '2018-04-05', '2018-04-06',\n",
      "               '2018-04-07', '2018-04-08', '2018-04-09', '2018-04-10',\n",
      "               '2018-04-11', '2018-04-12', '2018-04-13', '2018-04-14',\n",
      "               '2018-04-15', '2018-04-16', '2018-04-17', '2018-04-18',\n",
      "               '2018-04-19', '2018-04-20', '2018-04-21', '2018-04-22',\n",
      "               '2018-04-23', '2018-04-24'],\n",
      "              dtype='datetime64[ns]', name='date', freq=None)\n"
     ]
    }
   ],
   "source": [
    "# Remove corrupted dataframe and compute new date list\n",
    "data_df = df2[:-145]\n",
    "\n",
    "# Accessing dates\n",
    "i_date = data_df.index.get_level_values(0)          # get all dates\n",
    "idx_date = np.unique(data_df.index.get_level_values(0), return_index=True)[1]      # get index of unique dates\n",
    "date_list = i_date[idx_date]   # get list of all dates\n",
    "print('Unique dates',date_list)\n",
    "\n",
    "# Dates and times\n",
    "data_time = []\n",
    "for pl_i in idx_date:                             # create data_time indeces to have access later\n",
    "    time = data_df.loc[i_date[pl_i]].index\n",
    "    data_time.append(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 3am-3am data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 252\n"
     ]
    }
   ],
   "source": [
    "# Data points from 00:00:00 till 02:55:00\n",
    "tmp0 = data_df[sr0]\n",
    "tmp1 = tmp0[date_list[0].date()].loc[datetime.time(0,0,0):datetime.time(2,55,0)]\n",
    "tmp2 = tmp0[date_list[0].date()].loc[datetime.time(3,0,0):datetime.time(23,55,0)]\n",
    "print(len(tmp1), len(tmp2))\n",
    "\n",
    "X = data_df.values\n",
    "X = X[len(tmp1) : -len(tmp2)]     # this is my new data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create individual lists of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 49.0\n"
     ]
    }
   ],
   "source": [
    "# Here divide in 3 sections : data_sr0, data_sr1, data_sr2, and data_all = X\n",
    "nc = X.shape[0]/288\n",
    "print('Number of examples:', nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sr0 = X[:,0]\n",
    "data_sr1 = X[:,1]\n",
    "data_sr2 = X[:,2]\n",
    "\n",
    "data_sr0 = np.array(np.split(data_sr0,nc))      # Divide data in shape for plotting\n",
    "data_sr1 = np.array(np.split(data_sr1,nc))\n",
    "data_sr2 = np.array(np.split(data_sr2,nc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list_n = len(data_sr0)  # I have lost part of the data (last day)\n",
    "dates = date_list[0:len(data_sr0)]\n",
    "\n",
    "time_int = []\n",
    "for ind in range(X.shape[0]):\n",
    "    time = np.linspace(00.0, 23.55, num=len(data_sr0[0]))\n",
    "    time_int.append(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Save file\\nname_of_file_d = \"data_all\"\\ncompleteName_data = os.path.join(save_path, name_of_file_d + \".csv\") \\n\\nwith open(completeName_data, \"a\") as output:\\n    output.write(str(X))\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Save file\n",
    "name_of_file_d = \"data_all\"\n",
    "completeName_data = os.path.join(save_path, name_of_file_d + \".csv\") \n",
    "\n",
    "with open(completeName_data, \"a\") as output:\n",
    "    output.write(str(X))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting - Annotation case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "itera = dates\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "gs = gridspec.GridSpec(2, 3)\n",
    "\n",
    "fig = plt.figure()\n",
    "#plt.axis([0, 24, -3, 100])\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0]) # row 0, col 0\n",
    "ax2 = fig.add_subplot(gs[0, 1]) # row 0, col 1\n",
    "ax3 = fig.add_subplot(gs[0, 2]) # row 0, col 1\n",
    "ax4 = fig.add_subplot(gs[1, :]) # row 1, span all columns\n",
    "\n",
    "ax1.set_title('bf_03', fontdict=None, pad=None)\n",
    "ax2.set_title('bf_04', fontdict=None, pad=None)\n",
    "ax3.set_title('bl_ce193', fontdict=None, pad=None)\n",
    "ax4.set_title('bf_03 + bf_04 + bl_ce193', fontdict=None, pad=None)\n",
    "\n",
    "ax1.set_ylim([-3,100])\n",
    "ax2.set_ylim([-3,100])\n",
    "ax3.set_ylim([-3,100])\n",
    "ax4.set_ylim([-3,100])\n",
    "\n",
    "for pl_i in range(len(dates)): \n",
    "    ax1.plot(time_int[pl_i], data_sr0[pl_i], '#C0C0C0', lw=2)\n",
    "    ax2.plot(time_int[pl_i], data_sr1[pl_i], '#C0C0C0', lw=2)\n",
    "    ax3.plot(time_int[pl_i], data_sr2[pl_i],  '#C0C0C0',lw=2) \n",
    "    \n",
    "l, = ax1.plot(time_int[0], data_sr0[0], '#1E90FF', lw=2)     #the first one is the one in blue\n",
    "l2, = ax2.plot(time_int[0], data_sr1[0], '#8B008B')\n",
    "l3, = ax3.plot(time_int[0], data_sr2[0],'#FFDAB9')\n",
    "\n",
    "\n",
    "ll1, = ax4.plot(time_int[0], data_sr0[0], '#1E90FF')\n",
    "ll2, = ax4.plot(time_int[0], data_sr1[0], '#8B008B')\n",
    "ll3, = ax4.plot(time_int[0],  data_sr2[0], '#FFDAB9')\n",
    "\n",
    "\n",
    "############### Buttons widget  ####################\n",
    "\n",
    "class Index(object):\n",
    "    ind = 0\n",
    "\n",
    "    def next(self, event):\n",
    "        self.ind += 1\n",
    "        i = self.ind % len(itera)\n",
    "\n",
    "        #ydata0 will be the plot alone\n",
    "        ydata1 = data_sr0[i]   \n",
    "        ydata2 = data_sr1[i] \n",
    "        ydata3 = data_sr2[i]\n",
    "        xdata = time_int[i]          \n",
    "        \n",
    "        l.set_ydata(ydata1)\n",
    "        l.set_xdata(xdata)\n",
    "        l2.set_ydata(ydata2)\n",
    "        l2.set_xdata(xdata)\n",
    "        l3.set_ydata(ydata3)\n",
    "        l3.set_xdata(xdata)\n",
    "        \n",
    "        ll1.set_ydata(ydata1)\n",
    "        ll2.set_ydata(ydata2)\n",
    "        ll3.set_ydata(ydata3) \n",
    "        \n",
    "        ll1.set_xdata(xdata) \n",
    "        ll2.set_xdata(xdata)\n",
    "        ll3.set_xdata(xdata)\n",
    "        \n",
    "        plt.draw()\n",
    "\n",
    "    def prev(self, event):\n",
    "        self.ind -= 1\n",
    "        i = self.ind % len(itera)\n",
    "        \n",
    "        #ydata0 will be the plot alone\n",
    "        ydata1 = data_sr0[i]   \n",
    "        ydata2 = data_sr1[i] \n",
    "        ydata3 = data_sr2[i]\n",
    "        xdata = time_int[i]          \n",
    "        \n",
    "        l.set_ydata(ydata1)\n",
    "        l.set_xdata(xdata)\n",
    "        \n",
    "        l2.set_ydata(ydata2)\n",
    "        l2.set_xdata(xdata)\n",
    "        \n",
    "        l3.set_ydata(ydata3)\n",
    "        l3.set_xdata(xdata)\n",
    "\n",
    "        ll1.set_ydata(ydata1)\n",
    "        ll2.set_ydata(ydata2)\n",
    "        ll3.set_ydata(ydata3) \n",
    "\n",
    "        ll1.set_xdata(xdata) \n",
    "        ll2.set_xdata(xdata)\n",
    "        ll3.set_xdata(xdata)\n",
    "        \n",
    "        plt.draw()\n",
    "\n",
    "callback = Index()\n",
    "\n",
    "axprev = plt.axes([0.7, 0.05, 0.1, 0.075])\n",
    "axnext = plt.axes([0.81, 0.05, 0.1, 0.075])\n",
    "bnext = Button(axnext, 'Next')\n",
    "bnext.on_clicked(callback.next)\n",
    "\n",
    "bprev = Button(axprev, 'Previous')\n",
    "bprev.on_clicked(callback.prev)\n",
    "\n",
    "\"\"\"\n",
    "valore = '11'\n",
    "def presskey(event):\n",
    "    print('Pressed key = ', event.key)\n",
    "    #sys.stdout.flush()    \n",
    "    global valore \n",
    "    valore = event.key       \n",
    "    return valore\n",
    "\"\"\"\n",
    "\n",
    "def onselect1(xmin, xmax):\n",
    "    x = time_int[callback.ind % len(itera)]\n",
    "    y = data_sr0[callback.ind % len(itera)]\n",
    "    indmin1, indmax1 = np.searchsorted(x, (xmin, xmax))\n",
    "    indmax1 = min(len(x) - 1, indmax1)\n",
    "    thisx1 = x[indmin1:indmax1]\n",
    "    thisy1 = y[indmin1:indmax1]    \n",
    "    # save\n",
    "    np.savetxt(\"text1_0\", np.c_[thisx1, thisy1])\n",
    "        \n",
    "\n",
    "def onselect2(xmin, xmax):\n",
    "    x = time_int[callback.ind % len(itera)]\n",
    "    y = data_sr1[callback.ind % len(itera)]\n",
    "    indmin, indmax = np.searchsorted(x, (xmin, xmax))\n",
    "    indmax = min(len(x) - 1, indmax)\n",
    "    thisx = x[indmin:indmax]\n",
    "    thisy = y[indmin:indmax]    \n",
    "    # save\n",
    "    np.savetxt(\"text2\", np.c_[thisx, thisy])\n",
    "    \n",
    "\n",
    "def onselect3(xmin, xmax):\n",
    "    x = time_int[callback.ind % len(itera)]\n",
    "    y = data_sr2[callback.ind % len(itera)]\n",
    "    indmin, indmax = np.searchsorted(x, (xmin, xmax))\n",
    "    indmax = min(len(x) - 1, indmax)\n",
    "    thisx = x[indmin:indmax]\n",
    "    thisy = y[indmin:indmax]    \n",
    "    # save\n",
    "    np.savetxt(\"text3\", np.c_[thisx, thisy])\n",
    "\n",
    "def onselect4(xmin, xmax):\n",
    "    x = time_int[callback.ind % len(itera)]\n",
    "    y1 = data_sr0[callback.ind % len(itera)]\n",
    "    y2 = data_sr1[callback.ind % len(itera)]\n",
    "    y3 = data_sr2[callback.ind % len(itera)]\n",
    "    \n",
    "    indmin, indmax = np.searchsorted(x, (xmin, xmax))\n",
    "    indmax = min(len(x) - 1, indmax)\n",
    "    \n",
    "    thisx = x[indmin:indmax]\n",
    "    thisy1 = y1[indmin:indmax]\n",
    "    thisy2 = y2[indmin:indmax]\n",
    "    thisy3 = y3[indmin:indmax]       \n",
    "    # save\n",
    "    np.savetxt(\"text4_0\", np.c_[thisx, thisy1, thisy2, thisy3])\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "# Connect key event to figure\n",
    "fig.canvas.mpl_connect('key_press_event',presskey)\n",
    "\"\"\"\n",
    "\n",
    "#class1 = Onselect_1()\n",
    "\n",
    "spans1 = SpanSelector(ax1, onselect1, 'horizontal', useblit=False,\n",
    "                      rectprops=dict(alpha=0.5, facecolor='red') )\n",
    "span2 = SpanSelector(ax2, onselect2, 'horizontal', useblit=True,\n",
    "                    rectprops=dict(alpha=0.5, facecolor='red') )\n",
    "span3 = SpanSelector(ax3, onselect3, 'horizontal', useblit=True,\n",
    "                    rectprops=dict(alpha=0.5, facecolor='red') )\n",
    "span4 = SpanSelector(ax4, onselect4, 'horizontal', useblit=True,\n",
    "                    rectprops=dict(alpha=0.5, facecolor='red') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data  - CASE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor names: bf_07 , bl_ceb60 , bf_08\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "completePath = os.path.join(path_all, name_of_file2) \n",
    "df = pd.read_csv(completePath)\n",
    "\n",
    "\n",
    "df2 = df.copy(deep=True)\n",
    "df2['date'], df2['time'] = df2['time'].str.split(' ', 1).str\n",
    "\n",
    "sr0 = df2.keys()[1]\n",
    "sr1 = df2.keys()[2]\n",
    "sr2 = df2.keys()[3]\n",
    "print('Sensor names:',sr0,',', sr1,',', sr2)\n",
    "\n",
    "# Replace extreme values with zeros and create datetime\n",
    "# Replace extreme values with zeros and create datetime\n",
    "\n",
    "df2[sr0] = df2[sr0].replace([-9999.000], 0)\n",
    "df2[sr1] = df2[sr1].replace([-9999.000], 0)\n",
    "df2[sr2] = df2[sr2].replace([-9999.000], 0)\n",
    "df2['date'] = [x.date() for x in (pd.to_datetime([i for i in df2['date']], format='%Y-%m-%d'))] \n",
    "df2['time'] = [x.time() for x in (pd.to_datetime([i for i in df2['time']], format='%H:%M:%S'))]   # remove primes from the time\n",
    "df1 = df2.copy(deep=True)\n",
    "df2.set_index(['date','time'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique dates: DatetimeIndex(['2018-09-01', '2018-09-02', '2018-09-03', '2018-09-04',\n",
      "               '2018-09-05', '2018-09-06', '2018-09-07', '2018-09-08',\n",
      "               '2018-09-09', '2018-09-10', '2018-09-11', '2018-09-12',\n",
      "               '2018-09-13', '2018-09-14', '2018-09-15', '2018-09-16',\n",
      "               '2018-09-17', '2018-09-18', '2018-09-19', '2018-09-20',\n",
      "               '2018-09-21', '2018-09-22', '2018-09-23', '2018-09-24',\n",
      "               '2018-09-25', '2018-09-26', '2018-09-27', '2018-09-28',\n",
      "               '2018-09-29', '2018-09-30', '2018-10-01', '2018-10-02',\n",
      "               '2018-10-03', '2018-10-04', '2018-10-05', '2018-10-06',\n",
      "               '2018-10-07', '2018-10-08', '2018-10-09', '2018-10-10',\n",
      "               '2018-10-11', '2018-10-12', '2018-10-13', '2018-10-14',\n",
      "               '2018-10-15', '2018-10-16', '2018-10-17', '2018-10-18',\n",
      "               '2018-10-19', '2018-10-20', '2018-10-21', '2018-10-22',\n",
      "               '2018-10-23', '2018-10-24', '2018-10-25', '2018-10-26',\n",
      "               '2018-10-27', '2018-10-28', '2018-10-29', '2018-10-30',\n",
      "               '2018-10-31', '2018-11-01', '2018-11-02', '2018-11-03',\n",
      "               '2018-11-04', '2018-11-05', '2018-11-06', '2018-11-07',\n",
      "               '2018-11-08', '2018-11-09', '2018-11-10', '2018-11-11',\n",
      "               '2018-11-12'],\n",
      "              dtype='datetime64[ns]', name='date', freq=None)\n"
     ]
    }
   ],
   "source": [
    "# Accessing dates\n",
    "i_date = df2.index.get_level_values(0)          # get all dates\n",
    "idx_date = np.unique(df2.index.get_level_values(0), return_index=True)[1]      # get index of unique dates\n",
    "date_list = i_date[idx_date]   # get list of all dates\n",
    "print('Unique dates:',date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrupted date: 2018-10-16\n",
      "Corrupted date index: 12960\n",
      "Corrupted date shape: (290, 3)\n",
      "Corrupted date: 2018-11-12\n",
      "Corrupted date index: 20738\n",
      "Corrupted date shape: (243, 3)\n"
     ]
    }
   ],
   "source": [
    "df_bf_00 = df2[sr0]\n",
    "df_bf_01 = df2[sr1]\n",
    "df_bf_02 = df2[sr2]\n",
    "\n",
    "for pl_i in range(len(date_list)):\n",
    "    if len(df_bf_00[date_list[pl_i].date()].values) != 288:\n",
    "        print('Corrupted date:', date_list[pl_i].date())\n",
    "        print('Corrupted date index:',idx_date[pl_i])\n",
    "        print('Corrupted date shape:', df2.loc[date_list[pl_i].date()].shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.drop(index='2018-10-16', level=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df = df2[:-243]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique dates: DatetimeIndex(['2018-09-01', '2018-09-02', '2018-09-03', '2018-09-04',\n",
      "               '2018-09-05', '2018-09-06', '2018-09-07', '2018-09-08',\n",
      "               '2018-09-09', '2018-09-10', '2018-09-11', '2018-09-12',\n",
      "               '2018-09-13', '2018-09-14', '2018-09-15', '2018-09-16',\n",
      "               '2018-09-17', '2018-09-18', '2018-09-19', '2018-09-20',\n",
      "               '2018-09-21', '2018-09-22', '2018-09-23', '2018-09-24',\n",
      "               '2018-09-25', '2018-09-26', '2018-09-27', '2018-09-28',\n",
      "               '2018-09-29', '2018-09-30', '2018-10-01', '2018-10-02',\n",
      "               '2018-10-03', '2018-10-04', '2018-10-05', '2018-10-06',\n",
      "               '2018-10-07', '2018-10-08', '2018-10-09', '2018-10-10',\n",
      "               '2018-10-11', '2018-10-12', '2018-10-13', '2018-10-14',\n",
      "               '2018-10-15', '2018-10-17', '2018-10-18', '2018-10-19',\n",
      "               '2018-10-20', '2018-10-21', '2018-10-22', '2018-10-23',\n",
      "               '2018-10-24', '2018-10-25', '2018-10-26', '2018-10-27',\n",
      "               '2018-10-28', '2018-10-29', '2018-10-30', '2018-10-31',\n",
      "               '2018-11-01', '2018-11-02', '2018-11-03', '2018-11-04',\n",
      "               '2018-11-05', '2018-11-06', '2018-11-07', '2018-11-08',\n",
      "               '2018-11-09', '2018-11-10', '2018-11-11'],\n",
      "              dtype='datetime64[ns]', name='date', freq=None)\n"
     ]
    }
   ],
   "source": [
    "# Accessing dates\n",
    "i_date = data_df.index.get_level_values(0)          # get all dates\n",
    "idx_date = np.unique(data_df.index.get_level_values(0), return_index=True)[1]      # get index of unique dates\n",
    "date_list = i_date[idx_date]   # get list of all dates\n",
    "print('Unique dates:',date_list)\n",
    "df_bf_00 = data_df[sr0]\n",
    "df_bf_01 = data_df[sr1]\n",
    "df_bf_02 = data_df[sr2]\n",
    "\n",
    "for pl_i in range(len(date_list)):\n",
    "    if len(df_bf_00[date_list[pl_i].date()].values) != 288:\n",
    "        print('Corrupted date:', date_list[pl_i].date())\n",
    "        print('Corrupted date index:',idx_date[pl_i])\n",
    "        print('Corrupted date shape:', data_df.loc[date_list[pl_i].date()].shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 3am-3am data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 252\n"
     ]
    }
   ],
   "source": [
    "# Data points from 00:00:00 till 02:55:00\n",
    "tmp0 = data_df[sr0]\n",
    "tmp1 = tmp0[date_list[0].date()].loc[datetime.time(0,0,0):datetime.time(2,55,0)]\n",
    "tmp2 = tmp0[date_list[0].date()].loc[datetime.time(3,0,0):datetime.time(23,55,0)]\n",
    "print(len(tmp1), len(tmp2))\n",
    "\n",
    "X = data_df.values\n",
    "X = X[len(tmp1) : -len(tmp2)]     # this is my new data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create individual lists of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples: 70.0\n"
     ]
    }
   ],
   "source": [
    "# Here divide in 3 sections : data_sr0, data_sr1, data_sr2, and data_all = X\n",
    "nc = X.shape[0]/288\n",
    "print('Number of examples:', nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sr0 = X[:,0]\n",
    "data_sr1 = X[:,1]\n",
    "data_sr2 = X[:,2]\n",
    "\n",
    "data_sr0 = np.array(np.split(data_sr0,nc))      # Divide data in shape for plotting\n",
    "data_sr1 = np.array(np.split(data_sr1,nc))\n",
    "data_sr2 = np.array(np.split(data_sr2,nc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list_n = len(data_sr0)  # I have lost part of the data (last day)\n",
    "dates = date_list[0:len(data_sr0)]\n",
    "\n",
    "time_int = []\n",
    "for ind in range(X.shape[0]):\n",
    "    time = np.linspace(00.0, 23.55, num=len(data_sr0[0]))\n",
    "    time_int.append(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Save file\\nname_of_file_d = \"data_all\"\\ncompleteName_data = os.path.join(save_path, name_of_file_d + \".csv\") \\n\\nwith open(completeName_data, \"a\") as output:\\n    output.write(str(X))\\n'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Save file\n",
    "name_of_file_d = \"data_all\"\n",
    "completeName_data = os.path.join(save_path, name_of_file_d + \".csv\") \n",
    "\n",
    "with open(completeName_data, \"a\") as output:\n",
    "    output.write(str(X))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting - Annotation case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "itera = dates\n",
    "\n",
    "x = np.array([0,1,2,3])\n",
    "y = np.array([20,21,22,23])\n",
    "my_xticks = ['John','Arnold','Mavis','Matt']\n",
    "plt.xticks(x, my_xticks)\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "gs = gridspec.GridSpec(2, 3)\n",
    "\n",
    "fig = plt.figure()\n",
    "#plt.axis([0, 24, -3, 100])\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0]) # row 0, col 0\n",
    "ax2 = fig.add_subplot(gs[0, 1]) # row 0, col 1\n",
    "ax3 = fig.add_subplot(gs[0, 2]) # row 0, col 1\n",
    "ax4 = fig.add_subplot(gs[1, :]) # row 1, span all columns\n",
    "\n",
    "ax1.set_title('bf_07', fontdict=None, pad=None)\n",
    "ax2.set_title('bl_ceb60', fontdict=None, pad=None)\n",
    "ax3.set_title('bf_08', fontdict=None, pad=None)\n",
    "ax4.set_title('bf_07 + bl_ceb60 + bf_08', fontdict=None, pad=None)\n",
    "\n",
    "ax1.set_ylim([-3,100])\n",
    "ax2.set_ylim([-3,100])\n",
    "ax3.set_ylim([-3,100])\n",
    "ax4.set_ylim([-3,100])\n",
    "\n",
    "\n",
    "my_xticks = ['ciao']*size\n",
    "ax1.xticks = (my_xticks)\n",
    "\n",
    "\n",
    "\n",
    "for pl_i in range(len(dates)): \n",
    "    ax1.plot(time_int[pl_i], data_sr0[pl_i], '#C0C0C0', lw=2)\n",
    "    ax2.plot(time_int[pl_i], data_sr1[pl_i], '#C0C0C0', lw=2)\n",
    "    ax3.plot(time_int[pl_i], data_sr2[pl_i],  '#C0C0C0',lw=2) \n",
    "    \n",
    "l, = ax1.plot(time_int[0], data_sr0[0], '#1E90FF', lw=2)     #the first one is the one in blue\n",
    "l2, = ax2.plot(time_int[0], data_sr1[0], '#8B008B')\n",
    "l3, = ax3.plot(time_int[0], data_sr2[0],'#FFDAB9')\n",
    "\n",
    "\n",
    "ll1, = ax4.plot(time_int[0], data_sr0[0], '#1E90FF')\n",
    "ll2, = ax4.plot(time_int[0], data_sr1[0], '#8B008B')\n",
    "ll3, = ax4.plot(time_int[0],  data_sr2[0], '#FFDAB9')\n",
    "\n",
    "\n",
    "\n",
    "############### Buttons widget  ####################\n",
    "\n",
    "class Index(object):\n",
    "    ind = 0\n",
    "\n",
    "    def next(self, event):\n",
    "        self.ind += 1\n",
    "        i = self.ind % len(itera)\n",
    "\n",
    "        #ydata0 will be the plot alone\n",
    "        ydata1 = data_sr0[i]   \n",
    "        ydata2 = data_sr1[i] \n",
    "        ydata3 = data_sr2[i]\n",
    "        xdata = time_int[i]          \n",
    "        \n",
    "        l.set_ydata(ydata1)\n",
    "        l.set_xdata(xdata)\n",
    "        l2.set_ydata(ydata2)\n",
    "        l2.set_xdata(xdata)\n",
    "        l3.set_ydata(ydata3)\n",
    "        l3.set_xdata(xdata)\n",
    "        \n",
    "        ll1.set_ydata(ydata1)\n",
    "        ll2.set_ydata(ydata2)\n",
    "        ll3.set_ydata(ydata3) \n",
    "        \n",
    "        ll1.set_xdata(xdata) \n",
    "        ll2.set_xdata(xdata)\n",
    "        ll3.set_xdata(xdata)\n",
    "        \n",
    "        plt.draw()\n",
    "\n",
    "    def prev(self, event):\n",
    "        self.ind -= 1\n",
    "        i = self.ind % len(itera)\n",
    "        \n",
    "        #ydata0 will be the plot alone\n",
    "        ydata1 = data_sr0[i]   \n",
    "        ydata2 = data_sr1[i] \n",
    "        ydata3 = data_sr2[i]\n",
    "        xdata = time_int[i]          \n",
    "        \n",
    "        l.set_ydata(ydata1)\n",
    "        l.set_xdata(xdata)\n",
    "        \n",
    "        l2.set_ydata(ydata2)\n",
    "        l2.set_xdata(xdata)\n",
    "        \n",
    "        l3.set_ydata(ydata3)\n",
    "        l3.set_xdata(xdata)\n",
    "\n",
    "        ll1.set_ydata(ydata1)\n",
    "        ll2.set_ydata(ydata2)\n",
    "        ll3.set_ydata(ydata3) \n",
    "\n",
    "        ll1.set_xdata(xdata) \n",
    "        ll2.set_xdata(xdata)\n",
    "        ll3.set_xdata(xdata)\n",
    "        \n",
    "        plt.draw()\n",
    "\n",
    "callback = Index()\n",
    "\n",
    "axprev = plt.axes([0.7, 0.05, 0.1, 0.075])\n",
    "axnext = plt.axes([0.81, 0.05, 0.1, 0.075])\n",
    "bnext = Button(axnext, 'Next')\n",
    "bnext.on_clicked(callback.next)\n",
    "\n",
    "bprev = Button(axprev, 'Previous')\n",
    "bprev.on_clicked(callback.prev)\n",
    "\n",
    "\"\"\"\n",
    "valore = '11'\n",
    "def presskey(event):\n",
    "    print('Pressed key = ', event.key)\n",
    "    #sys.stdout.flush()    \n",
    "    global valore \n",
    "    valore = event.key       \n",
    "    return valore\n",
    "\"\"\"\n",
    "\n",
    "def onselect1(xmin, xmax):\n",
    "    x = time_int[callback.ind % len(itera)]\n",
    "    y = data_sr0[callback.ind % len(itera)]\n",
    "    indmin1, indmax1 = np.searchsorted(x, (xmin, xmax))\n",
    "    indmax1 = min(len(x) - 1, indmax1)\n",
    "    thisx1 = x[indmin1:indmax1]\n",
    "    thisy1 = y[indmin1:indmax1]    \n",
    "    # save\n",
    "    np.savetxt(\"text1_0\", np.c_[thisx1, thisy1])\n",
    "        \n",
    "\n",
    "def onselect2(xmin, xmax):\n",
    "    x = time_int[callback.ind % len(itera)]\n",
    "    y = data_sr1[callback.ind % len(itera)]\n",
    "    indmin, indmax = np.searchsorted(x, (xmin, xmax))\n",
    "    indmax = min(len(x) - 1, indmax)\n",
    "    thisx = x[indmin:indmax]\n",
    "    thisy = y[indmin:indmax]    \n",
    "    # save\n",
    "    np.savetxt(\"text2\", np.c_[thisx, thisy])\n",
    "    \n",
    "\n",
    "def onselect3(xmin, xmax):\n",
    "    x = time_int[callback.ind % len(itera)]\n",
    "    y = data_sr2[callback.ind % len(itera)]\n",
    "    indmin, indmax = np.searchsorted(x, (xmin, xmax))\n",
    "    indmax = min(len(x) - 1, indmax)\n",
    "    thisx = x[indmin:indmax]\n",
    "    thisy = y[indmin:indmax]    \n",
    "    # save\n",
    "    np.savetxt(\"text3\", np.c_[thisx, thisy])\n",
    "\n",
    "def onselect4(xmin, xmax):\n",
    "    x = time_int[callback.ind % len(itera)]\n",
    "    y1 = data_sr0[callback.ind % len(itera)]\n",
    "    y2 = data_sr1[callback.ind % len(itera)]\n",
    "    y3 = data_sr2[callback.ind % len(itera)]\n",
    "    \n",
    "    indmin, indmax = np.searchsorted(x, (xmin, xmax))\n",
    "    indmax = min(len(x) - 1, indmax)\n",
    "    \n",
    "    thisx = x[indmin:indmax]\n",
    "    thisy1 = y1[indmin:indmax]\n",
    "    thisy2 = y2[indmin:indmax]\n",
    "    thisy3 = y3[indmin:indmax]       \n",
    "    # save\n",
    "    np.savetxt(\"text4_0\", np.c_[thisx, thisy1, thisy2, thisy3])\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "# Connect key event to figure\n",
    "fig.canvas.mpl_connect('key_press_event',presskey)\n",
    "\"\"\"\n",
    "\n",
    "#class1 = Onselect_1()\n",
    "\n",
    "spans1 = SpanSelector(ax1, onselect1, 'horizontal', useblit=False,\n",
    "                      rectprops=dict(alpha=0.5, facecolor='red') )\n",
    "span2 = SpanSelector(ax2, onselect2, 'horizontal', useblit=True,\n",
    "                    rectprops=dict(alpha=0.5, facecolor='red') )\n",
    "span3 = SpanSelector(ax3, onselect3, 'horizontal', useblit=True,\n",
    "                    rectprops=dict(alpha=0.5, facecolor='red') )\n",
    "span4 = SpanSelector(ax4, onselect4, 'horizontal', useblit=True,\n",
    "                    rectprops=dict(alpha=0.5, facecolor='red') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post processing of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating individual and collective labelled data\n",
    "\n",
    "bf_07 = pd.DataFrame(df2['bf_07'])\n",
    "bf_08 = pd.DataFrame(df2['bf_08'])\n",
    "bl_ceb60 = pd.DataFrame(df2['bl_ceb60'])\n",
    "bf_bl_all = df2.copy(deep=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0          1         2         3         4         5         6    \\\n",
      "0         0  0.0820557  0.164111  0.246167  0.328223  0.410279  0.492334   \n",
      "1  00:00:00   00:05:00  00:10:00  00:15:00  00:20:00  00:25:00  00:30:00   \n",
      "\n",
      "        7         8         9      ...          278       279       280  \\\n",
      "0   0.57439  0.656446  0.738502    ...      22.8115   22.8936   22.9756   \n",
      "1  00:35:00  00:40:00  00:45:00    ...     23:10:00  23:15:00  23:20:00   \n",
      "\n",
      "        281       282       283       284       285       286       287  \n",
      "0   23.0577   23.1397   23.2218   23.3038   23.3859   23.4679     23.55  \n",
      "1  23:25:00  23:30:00  23:35:00  23:40:00  23:45:00  23:50:00  23:55:00  \n",
      "\n",
      "[2 rows x 288 columns]\n",
      "00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Index of Date and time for correspondece\n",
    "time_tmp = np.array(data_time[1])\n",
    "arrsy = [time_int[1], time_tmp]\n",
    "dfy = np.array(arrsy)\n",
    "dfy = pd.DataFrame(data=dfy)  # 1st row as the column names\n",
    "print(dfy)\n",
    "print(dfy[0].iloc[1])    # get access to time\n",
    "#dfy.iloc[1,0]\n",
    "#dfy.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#idx_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>12.2263</td>\n",
       "      <td>19.323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>12.3084</td>\n",
       "      <td>20.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>12.3904</td>\n",
       "      <td>20.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>12.4725</td>\n",
       "      <td>20.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>12.5545</td>\n",
       "      <td>20.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>12.6366</td>\n",
       "      <td>20.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>12.7186</td>\n",
       "      <td>19.611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>12.8007</td>\n",
       "      <td>19.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>12.8828</td>\n",
       "      <td>19.395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>12.9648</td>\n",
       "      <td>19.567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>13.0469</td>\n",
       "      <td>18.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>13.1289</td>\n",
       "      <td>18.777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>13.211</td>\n",
       "      <td>18.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>13.293</td>\n",
       "      <td>18.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>13.3751</td>\n",
       "      <td>18.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>13.4571</td>\n",
       "      <td>18.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>13.5392</td>\n",
       "      <td>18.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>13.6213</td>\n",
       "      <td>18.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>13.7033</td>\n",
       "      <td>18.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>13.7854</td>\n",
       "      <td>18.602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>13.8674</td>\n",
       "      <td>17.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>13.9495</td>\n",
       "      <td>18.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>14.0315</td>\n",
       "      <td>18.841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>14.1136</td>\n",
       "      <td>18.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>14.1956</td>\n",
       "      <td>18.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>14.2777</td>\n",
       "      <td>18.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>14.3598</td>\n",
       "      <td>19.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>14.4418</td>\n",
       "      <td>22.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>14.5239</td>\n",
       "      <td>22.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>14.6059</td>\n",
       "      <td>22.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>20.1857</td>\n",
       "      <td>14.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>20.2678</td>\n",
       "      <td>14.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>20.3498</td>\n",
       "      <td>14.564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>20.4319</td>\n",
       "      <td>14.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>20.5139</td>\n",
       "      <td>13.243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>20.596</td>\n",
       "      <td>13.836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>20.678</td>\n",
       "      <td>12.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>20.7601</td>\n",
       "      <td>12.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>20.8422</td>\n",
       "      <td>12.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>20.9242</td>\n",
       "      <td>13.264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>21.0063</td>\n",
       "      <td>13.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>21.0883</td>\n",
       "      <td>14.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>21.1704</td>\n",
       "      <td>13.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>21.2524</td>\n",
       "      <td>14.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>21.3345</td>\n",
       "      <td>13.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>21.4166</td>\n",
       "      <td>13.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>21.4986</td>\n",
       "      <td>13.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>21.5807</td>\n",
       "      <td>13.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>21.6627</td>\n",
       "      <td>13.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>21.7448</td>\n",
       "      <td>12.241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>21.8268</td>\n",
       "      <td>12.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>21.9089</td>\n",
       "      <td>12.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>21.9909</td>\n",
       "      <td>12.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>22.073</td>\n",
       "      <td>12.577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>22.1551</td>\n",
       "      <td>12.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>22.2371</td>\n",
       "      <td>12.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>22.3192</td>\n",
       "      <td>12.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>22.4012</td>\n",
       "      <td>11.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>22.4833</td>\n",
       "      <td>11.566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>22.5653</td>\n",
       "      <td>11.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0        1       2\n",
       "0    2018-09-01  12.2263  19.323\n",
       "1    2018-09-01  12.3084  20.899\n",
       "2    2018-09-01  12.3904  20.263\n",
       "3    2018-09-01  12.4725  20.914\n",
       "4    2018-09-01  12.5545  20.715\n",
       "5    2018-09-01  12.6366  20.599\n",
       "6    2018-09-01  12.7186  19.611\n",
       "7    2018-09-01  12.8007   19.27\n",
       "8    2018-09-01  12.8828  19.395\n",
       "9    2018-09-01  12.9648  19.567\n",
       "10   2018-09-01  13.0469   18.79\n",
       "11   2018-09-01  13.1289  18.777\n",
       "12   2018-09-01   13.211  18.799\n",
       "13   2018-09-01   13.293  18.393\n",
       "14   2018-09-01  13.3751  18.281\n",
       "15   2018-09-01  13.4571  18.289\n",
       "16   2018-09-01  13.5392  18.176\n",
       "17   2018-09-01  13.6213  18.791\n",
       "18   2018-09-01  13.7033  18.934\n",
       "19   2018-09-01  13.7854  18.602\n",
       "20   2018-09-01  13.8674  17.936\n",
       "21   2018-09-01  13.9495  18.225\n",
       "22   2018-09-01  14.0315  18.841\n",
       "23   2018-09-01  14.1136  18.573\n",
       "24   2018-09-01  14.1956  18.337\n",
       "25   2018-09-01  14.2777  18.445\n",
       "26   2018-09-01  14.3598  19.864\n",
       "27   2018-09-01  14.4418  22.107\n",
       "28   2018-09-01  14.5239  22.695\n",
       "29   2018-09-01  14.6059  22.165\n",
       "..          ...      ...     ...\n",
       "97   2018-09-01  20.1857  14.288\n",
       "98   2018-09-01  20.2678  14.712\n",
       "99   2018-09-01  20.3498  14.564\n",
       "100  2018-09-01  20.4319   14.92\n",
       "101  2018-09-01  20.5139  13.243\n",
       "102  2018-09-01   20.596  13.836\n",
       "103  2018-09-01   20.678  12.601\n",
       "104  2018-09-01  20.7601  12.624\n",
       "105  2018-09-01  20.8422  12.759\n",
       "106  2018-09-01  20.9242  13.264\n",
       "107  2018-09-01  21.0063   13.78\n",
       "108  2018-09-01  21.0883  14.109\n",
       "109  2018-09-01  21.1704  13.899\n",
       "110  2018-09-01  21.2524  14.253\n",
       "111  2018-09-01  21.3345  13.335\n",
       "112  2018-09-01  21.4166  13.857\n",
       "113  2018-09-01  21.4986  13.138\n",
       "114  2018-09-01  21.5807   13.18\n",
       "115  2018-09-01  21.6627  13.492\n",
       "116  2018-09-01  21.7448  12.241\n",
       "117  2018-09-01  21.8268  12.011\n",
       "118  2018-09-01  21.9089  12.282\n",
       "119  2018-09-01  21.9909  12.926\n",
       "120  2018-09-01   22.073  12.577\n",
       "121  2018-09-01  22.1551  12.415\n",
       "122  2018-09-01  22.2371  12.318\n",
       "123  2018-09-01  22.3192   12.31\n",
       "124  2018-09-01  22.4012  11.935\n",
       "125  2018-09-01  22.4833  11.566\n",
       "126  2018-09-01  22.5653   11.91\n",
       "\n",
       "[127 rows x 3 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identified index of anomalous data\n",
    "b = np.transpose(a)\n",
    "pd.DataFrame(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here do the postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
