{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation tool for time series data\n",
    "\n",
    "By: Stefania Russo, Kris Villez\n",
    "Copyright: 2018, distributed with BSD3 license "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage\n",
    "- Create folder called \"labels\" into each case folder\n",
    "- Change path of  working directory path_all\n",
    "- Select Case (1 or 2)\n",
    "- Select data file name_of_file\n",
    "- Run the cells\n",
    "- After performing the annotation, close the plot and run the last cell 'Save labelled data'\n",
    "- Note: if the user wants to change any of his selections, he needs to move forward to the next plot by clicking 'Next', perform a selection of the anomalous data, and then go back and restart.\n",
    "\n",
    "# Usage as .py script\n",
    "\n",
    "- Create folder called \"labels\" into each case folder\n",
    "- Change path of  working directory path_all\n",
    "- Open terminal and go to the path of the .py file\n",
    "- On terminal write : python name_of_annotation_tool.py\n",
    "- Select Case + enter\n",
    "- Select data file name_of_file + enter\n",
    "- After performing the annotation, close the plot.\n",
    "- Restart\n",
    "- Note: if the user wants to change any of his selections, he needs to move forward to the next plot by clicking 'Next', perform a selection of the anomalous data, and then go back and restart.\n",
    "\n",
    "\n",
    "# Usage as .ipyn script\n",
    "- select notebook_type = 'ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The challenge\n",
    "\n",
    "In the context of the ADASen project, we want to address research questions regarding the utility of supervised and unsupervised machine learning models in anomaly detection for environmental systems. We have therefore selected a range of anomaly detection methods for benchmarking on data sets produced by six infrastructures at Eawag.\n",
    "\n",
    "Critical to the benchmarking is the availability of fully labelled training and test data sets of normal and abnormal behavior in environmental data. \n",
    "An annotation tool has therefore being developed to perform the labelling procedure.\n",
    "\n",
    "This notebook shows an application of the labelling procedure to time series data. Here, each time series is a univariate 24h signal from ......\n",
    "\n",
    "Each series is visualised as a 24h time series.\n",
    "\n",
    "## Current method\n",
    "\n",
    "Below are described the steps for data access, data preparation, visualization and labelling procedure.\n",
    "\n",
    "- The data is in the form of .csv data files. Each data file consists of many 24h sets across 2 sensors.\n",
    "\n",
    "    - if missing values are already replaced with NaNs\n",
    "    - If none, replace missing values with NaNs\n",
    "    - Decide if removing dates with Missing Values\n",
    "    - Perform Annotation\n",
    "\n",
    "- The labelling procedure starts and the first plots are displayed. The 3 plots at the top are univariate sensor signals, where the bottom plot shows a collection of these signals.  \n",
    "\n",
    "- The annotation tool allows the labelling expert to interactivelly select multiple portions of the time series by moving through the data with the mouse cursor.\n",
    "\n",
    "- Each time the button 'Next' is clicked, all the selected areas (time index and sensor value) are saved together with information about the date stamp date. At the end of the procedure, the user can easily access to the anomaly labels in an easy manner.\n",
    "\n",
    "- When the process is over, the plots need to be closed and then the cell 'Save labelled data' hs to be run \n",
    "\n",
    "- Note: if the user wants to change any of his selections, he needs to move forward to the next plot by clicking 'Next', perform a selection of the anomalous data, and then go back and restart.\n",
    "\n",
    "\n",
    " \n",
    "# NOTE: \n",
    "## This is an alpha version of the labelling tool! Please provide any feedback\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iniziatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.widgets import Button\n",
    "from matplotlib.widgets import SpanSelector\n",
    "import itertools\n",
    "import datetime as datetime\n",
    "from datetime import timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_type = 'ipynb'    #ipynb   #py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select Case (1: GAK (p3,p4)  2: Pressure T1 T2 (p1,p2)):  1\n",
      "Please enter the file name: 06_June 2018\n"
     ]
    }
   ],
   "source": [
    "case_from_terminal = input('Please select Case (1: GAK (p3,p4)  2: Pressure T1 T2 (p1,p2)):  ')\n",
    "text_from_terminal = input(\"Please enter the file name: \")  # Python 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_all = ('/Users/russoste/Desktop/my_git_repos/00_Data/04_Nest/data_raw/')\n",
    "save_path = path_all     # Destination folder to for labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label month by month\n",
    "\n",
    "# Select Case\n",
    "# Case = 2     # case 1: GAK (p3,p4),       case 2: Pressure T1 T2 (p1,p2)\n",
    "\n",
    "if case_from_terminal == '1':\n",
    "    folder = 'data_pressure_sensor_GAK/'\n",
    "    \n",
    "if case_from_terminal == '2':\n",
    "    folder = 'data_pressure_sensors_T1_T2/' \n",
    "    \n",
    "Case = int(case_from_terminal)    \n",
    "    \n",
    "name_of_file = text_from_terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_file1 = name_of_file + \".csv\"\n",
    "name_of_file_l1 =  folder + 'labels/' + name_of_file + '_labels_'\n",
    "name_of_file_l1_time = folder + 'labels/' + name_of_file + '_labels_time'\n",
    "\n",
    "completePath = os.path.join(path_all, folder, name_of_file1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now working with :  data_pressure_sensor_GAK/  file:  06_June 2018\n"
     ]
    }
   ],
   "source": [
    "print ('Now working with : ', folder, ' file: ', name_of_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and basic sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(completePath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor names: p3 , p4\n"
     ]
    }
   ],
   "source": [
    "df2 = df.copy(deep=True)\n",
    "\n",
    "sr0 = df2.keys()[2]\n",
    "sr1 = df2.keys()[3]\n",
    "print('Sensor names:',sr0,',', sr1)\n",
    "\n",
    "# if (df2.shape[0]%8640 !=0):\n",
    "    # print('Missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Datetime'] = df2['day'] + ' ' + df2['hour']\n",
    "df2['Datetime_'] = [x for x in (pd.to_datetime([i for i in df2['Datetime']], format='%d.%m.%Y %H:%M:%S'))] \n",
    "df3 = df2.resample('10S', on='Datetime_', base=10).mean()\n",
    "\n",
    "if (df3.shape[0]%8640 !=0):\n",
    "    print('Missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['day'] = [x.date() for x in df3['Datetime_']] \n",
    "df3['time'] = [x.time() for x in df3['Datetime_']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.copy(deep=True)\n",
    "df4.set_index(['day','time'], inplace=True)\n",
    "\n",
    "df_bf_00 = df4[sr0]\n",
    "df_bf_01 = df4[sr1]\n",
    "df_bf_02 = df4[sr0] - df4[sr1]\n",
    "\n",
    "df4.drop(columns ='Datetime_', inplace=True)\n",
    "df2 = df4.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Accessing dates\n",
    "i_date = df2.index.get_level_values(0)                                      # get all dates\n",
    "idx_date = np.unique(df2.index.get_level_values(0), return_index=True)[1]      # get index of unique dates\n",
    "date_list = i_date[idx_date]   # get list of all dates\n",
    "# print('Unique dates:',date_list)\n",
    "\n",
    "# for pl_i in range(len(date_list)):\n",
    "#     if len(df_bf_00[date_list[pl_i].date()].values) != 8640:\n",
    "#         print('Corrupted date:', date_list[pl_i].date())\n",
    "#         print('Corrupted date index:',pl_i)\n",
    "#         print('Corrupted date shape:', df2.loc[date_list[pl_i].date()].shape)  \n",
    "# print ('Number of days:', df2.shape[0]/8640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates and times\n",
    "data_df2 = df2.copy()\n",
    "\n",
    "data_time = []\n",
    "for pl_i in idx_date:                             # create data_time indeces to have access later\n",
    "    time = data_df2.loc[i_date[pl_i]].index\n",
    "    data_time.append(time)                        # associated to every date segment\n",
    "    \n",
    "time_int = [np.linspace(1, 8640, num = 8640, dtype=int) for _ in range(len(date_list))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_ipython().run_line_magic('matplotlib', 'tk')\n",
    "\n",
    "if notebook_type == 'ipynb':\n",
    "    %matplotlib tk\n",
    "\n",
    "if notebook_type == 'py':\n",
    "    import matplotlib as mpl\n",
    "    mpl.use('Qt5Agg')\n",
    "\n",
    "data1 = []\n",
    "data2 = []\n",
    "data123 = []\n",
    "\n",
    "itera = date_list\n",
    "\n",
    "\n",
    "\n",
    "# ########################################\n",
    "# # added\n",
    "\n",
    "# import matplotlib as mpl\n",
    "# mpl.use('Qt5Agg')\n",
    "# #######################################\n",
    "\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "fig = plt.figure()\n",
    "#plt.axis([0, 24, -3, 100])\n",
    "\n",
    "\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0]) # row 0, col 0\n",
    "ax2 = fig.add_subplot(gs[0, 1]) # row 0, col 1\n",
    "ax4 = fig.add_subplot(gs[1, :]) # row 1, span all columns\n",
    "\n",
    "ax1.set_title(sr0, fontdict=None, pad=None)\n",
    "ax2.set_title(sr1, fontdict=None, pad=None)\n",
    "full = sr0 + ' '+ sr1\n",
    "ax4.set_title(full, fontdict=None, pad=None)\n",
    "\n",
    "fig.suptitle(str(date_list[0].date()), fontsize=12)\n",
    "\n",
    "\n",
    "if Case == 1:\n",
    "    ax1.set_ylim([-3,100])\n",
    "    ax2.set_ylim([-3,100])\n",
    "    ax4.set_ylim([-3,100])\n",
    "    \n",
    "if Case == 2:\n",
    "    ax1.set_ylim([40,150])\n",
    "    ax2.set_ylim([40,150])\n",
    "    ax4.set_ylim([40,150])\n",
    "\n",
    "for pl_i in range(len(date_list)): \n",
    "    ax1.plot(time_int[pl_i], df_bf_00[date_list[pl_i].date()].values, '#C0C0C0', lw=2)\n",
    "    ax2.plot(time_int[pl_i], df_bf_01[date_list[pl_i].date()].values, '#C0C0C0', lw=2)\n",
    "    \n",
    "l, = ax1.plot(time_int[0], df_bf_00[date_list[0].date()].values, '#1E90FF', lw=2)     #the first one is the one in blue\n",
    "l2, = ax2.plot(time_int[0], df_bf_01[date_list[0].date()].values, '#8B008B')\n",
    "\n",
    "\n",
    "###########################\n",
    "if Case == 1:\n",
    "    ll1, = ax4.plot(time_int[0], df_bf_00[date_list[0].date()].values, '#C0C0C0')\n",
    "    ll2, = ax4.plot(time_int[0], df_bf_01[date_list[0].date()].values, '#C0C0C0')\n",
    "    ll3, = ax4.plot(time_int[0], df_bf_02[date_list[0].date()].values, '#31a354')   # add difference4 plot\n",
    "\n",
    "if Case == 2:\n",
    "    ll1, = ax4.plot(time_int[0], df_bf_00[date_list[0].date()].values, '#1E90FF')\n",
    "    ll2, = ax4.plot(time_int[0], df_bf_01[date_list[0].date()].values, '#8B008B')\n",
    "\n",
    "############### Buttons widget  ####################\n",
    "\n",
    "class Index(object):\n",
    "    ind = 0\n",
    "\n",
    "    def next(self, event):\n",
    "        self.ind += 1\n",
    "        i = self.ind % len(itera)\n",
    "\n",
    "        #ydata0 will be the plot alone\n",
    "        ydata1 = df_bf_00[date_list[i].date()].values   \n",
    "        ydata2 = df_bf_01[date_list[i].date()].values \n",
    "        ydata3 = df_bf_02[date_list[i].date()].values \n",
    "        \n",
    "        xdata = time_int[i]          \n",
    "        \n",
    "        l.set_ydata(ydata1)\n",
    "        l.set_xdata(xdata)\n",
    "        l2.set_ydata(ydata2)\n",
    "        l2.set_xdata(xdata)\n",
    "        \n",
    "        if Case == 1:\n",
    "            ll1.set_ydata(ydata1)\n",
    "            ll2.set_ydata(ydata2)\n",
    "            ll3.set_ydata(ydata3)\n",
    "            ll1.set_xdata(xdata) \n",
    "            ll2.set_xdata(xdata)\n",
    "            ll3.set_xdata(xdata)\n",
    "        \n",
    "        if Case == 2:                \n",
    "            ll1.set_ydata(ydata1)\n",
    "            ll2.set_ydata(ydata2)\n",
    "            ll1.set_xdata(xdata) \n",
    "            ll2.set_xdata(xdata)\n",
    "        \n",
    "        \n",
    "        if (i == (0)):\n",
    "            fig.suptitle('End of data files - restarting with data file ' + str(date_list[i].date()), fontsize=12)\n",
    "        else: \n",
    "            fig.suptitle(str(date_list[i].date()), fontsize=12)\n",
    "            \n",
    "        plt.draw()\n",
    "\n",
    "    def prev(self, event):\n",
    "        self.ind -= 1\n",
    "        i = self.ind % len(itera)\n",
    "        \n",
    "        #ydata0 will be the plot alone\n",
    "        ydata1 = df_bf_00[date_list[i].date()].values \n",
    "        ydata2 = df_bf_01[date_list[i].date()].values \n",
    "        ydata3 = df_bf_02[date_list[i].date()].values \n",
    "        \n",
    "        xdata = time_int[i]  \n",
    "        \n",
    "        l.set_ydata(ydata1)\n",
    "        l.set_xdata(xdata)\n",
    "        \n",
    "        l2.set_ydata(ydata2)\n",
    "        l2.set_xdata(xdata)\n",
    "        \n",
    "        if Case == 1:\n",
    "            ll1.set_ydata(ydata1)\n",
    "            ll2.set_ydata(ydata2)\n",
    "            ll3.set_ydata(ydata3)\n",
    "            ll1.set_xdata(xdata) \n",
    "            ll2.set_xdata(xdata)\n",
    "            ll3.set_xdata(xdata)\n",
    "        \n",
    "        if Case == 2:                \n",
    "            ll1.set_ydata(ydata1)\n",
    "            ll2.set_ydata(ydata2)\n",
    "            ll1.set_xdata(xdata) \n",
    "            ll2.set_xdata(xdata)\n",
    "        \n",
    "\n",
    "        if (i == (0)):\n",
    "            fig.suptitle('End of data files - restarting with data file ' + str(date_list[i].date()), fontsize=12)\n",
    "        else: \n",
    "            fig.suptitle(str(date_list[i].date()), fontsize=12)\n",
    "            \n",
    "        plt.draw()\n",
    "\n",
    "callback = Index()\n",
    "\n",
    "axprev = plt.axes([0.7, 0.05, 0.1, 0.075])\n",
    "axnext = plt.axes([0.81, 0.05, 0.1, 0.075])\n",
    "bnext = Button(axnext, 'Next')\n",
    "bnext.on_clicked(callback.next)\n",
    "\n",
    "bprev = Button(axprev, 'Previous')\n",
    "bprev.on_clicked(callback.prev)\n",
    "\n",
    "\"\"\"\n",
    "valore = '11'\n",
    "def presskey(event):\n",
    "    print('Pressed key = ', event.key)\n",
    "    #sys.stdout.flush()    \n",
    "    global valore \n",
    "    valore = event.key       \n",
    "    return valore\n",
    "\"\"\"\n",
    "\n",
    "def onselect1(xmin, xmax):\n",
    "    x = time_int[callback.ind % len(itera)]\n",
    "    y = df_bf_00[date_list[callback.ind % len(itera)].date()].values \n",
    "    today = date_list[callback.ind % len(itera)]\n",
    "   \n",
    "    indmin1, indmax1 = np.searchsorted(x, (xmin, xmax))\n",
    "    indmax1 = min(len(x) - 1, indmax1)\n",
    "    thisx = x[indmin1:indmax1]\n",
    "    thisy = y[indmin1:indmax1]    \n",
    "    nplist = np.array([today.date() for i in range(len(thisx))])\n",
    "        \n",
    "    a1 = np.c_[nplist, thisx, thisy]\n",
    "    global data1\n",
    "    data1.extend(a1)\n",
    "    #np.savetxt(completeName_label_1, data1)\n",
    "\n",
    "        \n",
    "\n",
    "def onselect2(xmin, xmax):\n",
    "    x = time_int[callback.ind % len(itera)]\n",
    "    y = df_bf_01[date_list[callback.ind % len(itera)].date()].values \n",
    "    today = date_list[callback.ind % len(itera)]\n",
    "    \n",
    "    indmin, indmax = np.searchsorted(x, (xmin, xmax))\n",
    "    indmax = min(len(x) - 1, indmax)\n",
    "    thisx = x[indmin:indmax]\n",
    "    thisy = y[indmin:indmax]\n",
    "    nplist = np.array([today.date() for i in range(len(thisx))])\n",
    "    \n",
    "    a2 = np.c_[nplist, thisx, thisy]\n",
    "    global data2\n",
    "    data2.extend(a2)\n",
    "    \n",
    "\n",
    "def onselect4(xmin, xmax):\n",
    "    x = time_int[callback.ind % len(itera)]\n",
    "    y1 = df_bf_00[date_list[callback.ind % len(itera)].date()].values \n",
    "    y2 = df_bf_01[date_list[callback.ind % len(itera)].date()].values\n",
    "    today = date_list[callback.ind % len(itera)]\n",
    "    \n",
    "    indmin, indmax = np.searchsorted(x, (xmin, xmax))\n",
    "    indmax = min(len(x) - 1, indmax)\n",
    "    \n",
    "    thisx = x[indmin:indmax]\n",
    "    thisy1 = y1[indmin:indmax]\n",
    "    thisy2 = y2[indmin:indmax]\n",
    "    nplist = np.array([today.date() for i in range(len(thisx))])\n",
    "        \n",
    "    # save\n",
    "    a123 = np.c_[nplist, thisx, thisy1, thisy2]\n",
    "    global data123\n",
    "    data123.extend(a123)\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "# Connect key event to figure\n",
    "fig.canvas.mpl_connect('key_press_event',presskey)\n",
    "\"\"\"\n",
    "\n",
    "#class1 = Onselect_1()\n",
    "\n",
    "spans1 = SpanSelector(ax1, onselect1, 'horizontal', useblit=False,\n",
    "                      rectprops=dict(alpha=0.5, facecolor='red'), span_stays=True)\n",
    "span2 = SpanSelector(ax2, onselect2, 'horizontal', useblit=True,\n",
    "                    rectprops=dict(alpha=0.5, facecolor='red'), span_stays=True )\n",
    "span4 = SpanSelector(ax4, onselect4, 'horizontal', useblit=True,\n",
    "                    rectprops=dict(alpha=0.5, facecolor='red') , span_stays=True)\n",
    "\n",
    "\n",
    "########################################\n",
    "if notebook_type == 'py':\n",
    "    # added\n",
    "    plt.show()\n",
    "########################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame(data1, columns=['day','time_m', sr0])\n",
    "data2 = pd.DataFrame(data2, columns=['day','time_m', sr1])\n",
    "data123 = pd.DataFrame(data123, columns=['day','time_m', sr0, sr1])\n",
    "\n",
    "data1.to_csv(os.path.join(save_path,name_of_file_l1+sr0 + \".csv\") )\n",
    "data2.to_csv(os.path.join(save_path,name_of_file_l1+sr1 + \".csv\") )\n",
    "data123.to_csv(os.path.join(save_path,name_of_file_l1+sr0+sr1+ \".csv\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to time labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_dup(datal):\n",
    "    if (len(datal))==0:\n",
    "        return datal.copy(deep=True)\n",
    "    list_org = [str(i) for i in datal['day'].values]\n",
    "    states = [list_org[-1]]\n",
    "    index_keep =[True]\n",
    "\n",
    "    for i in range(len(list_org)-2,-1,-1):\n",
    "        if list_org[i]!=list_org[i+1] and list_org[i] not in states:\n",
    "            states.extend([list_org[i]])\n",
    "            index_keep.append(True) \n",
    "\n",
    "        elif list_org[i]!=list_org[i+1] and list_org[i] in states:\n",
    "            index_keep.append(False)\n",
    "\n",
    "        elif list_org[i]==list_org[i+1] and index_keep[len(list_org)-2-i]==False:   # check\n",
    "            index_keep.append(False)\n",
    "\n",
    "        elif list_org[i]==list_org[i+1] and list_org[i] in states:\n",
    "            index_keep.append(True)\n",
    "            \n",
    "    index_keep.reverse()\n",
    "    #index_keep = rem_dup(datal)\n",
    "    datall = datal[index_keep]\n",
    "    return datall\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_l = rem_dup(data1)\n",
    "data2_l = rem_dup(data2)\n",
    "data123_l = rem_dup(data123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df2.reset_index()\n",
    "\n",
    "data_df_s1 = data_df.drop([sr1], axis=1)\n",
    "data_df_s2 = data_df.drop([sr0], axis=1)\n",
    "data_df_s3 = data_df.copy()\n",
    "\n",
    "data_df_s1['time_m'] = np.reshape(time_int, 8640*len(time_int))\n",
    "data_df_s2['time_m'] = np.reshape(time_int, 8640*len(time_int))\n",
    "data_df_s3['time_m'] = np.reshape(time_int, 8640*len(time_int))\n",
    "\n",
    "data_df_s1['day'] = [x.date() for x in data_df_s1['day']] \n",
    "data_df_s2['day'] = [x.date() for x in data_df_s2['day']] \n",
    "data_df_s3['day'] = [x.date() for x in data_df_s3['day']] \n",
    "\n",
    "data1_l.drop(columns = sr0, inplace=True)\n",
    "data2_l.drop(columns = sr1, inplace=True)\n",
    "data123_l.drop(columns =[sr0, sr1], inplace=True)\n",
    "\n",
    "labels_df_1 = pd.merge(data_df_s1, data1_l, on = ['day', 'time_m'], how='left', indicator=True)\n",
    "labels_df_2 = pd.merge(data_df_s2, data2_l, on = ['day', 'time_m'], how='left', indicator=True)\n",
    "labels_df_123 = pd.merge(data_df_s3, data123_l, on = ['day', 'time_m'], how='left', indicator=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ADD zeros and ones with dictionary mapping\n",
    "\n",
    "mapper_dict = {'left_only': 0, 'both': 1}\n",
    "\n",
    "def mp(entry):\n",
    "    \"\"\"\n",
    "    maps new values\n",
    "    \"\"\"\n",
    "    return mapper_dict[entry] if entry in mapper_dict else entry\n",
    "mp = np.vectorize(mp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df_1 ['_merge'] = mp(labels_df_1['_merge'])\n",
    "labels_df_2 ['_merge'] = mp(labels_df_2['_merge'])\n",
    "labels_df_123 ['_merge'] = mp(labels_df_123['_merge'])\n",
    "\n",
    "labels_df_1 = labels_df_1.rename(index=str, columns={\"_merge\": \"Anomaly\"})\n",
    "labels_df_2 = labels_df_2.rename(index=str, columns={\"_merge\": \"Anomaly\"})\n",
    "labels_df_123 = labels_df_123.rename(index=str, columns={\"_merge\": \"Anomaly\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df_1.drop(['time_m'], axis=1, inplace=True)\n",
    "labels_df_2.drop(['time_m'], axis=1, inplace=True)\n",
    "labels_df_123.drop(['time_m'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df_1.to_csv(os.path.join(save_path, name_of_file_l1_time+sr0 + \".csv\") )\n",
    "labels_df_2.to_csv(os.path.join(save_path, name_of_file_l1_time+sr1 + \".csv\") )\n",
    "labels_df_123.to_csv(os.path.join(save_path, name_of_file_l1_time+sr0+sr1 + \".csv\") )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>p4</th>\n",
       "      <th>Anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:00:10</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:00:20</td>\n",
       "      <td>13.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:00:30</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:00:40</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:00:50</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:01:00</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:01:10</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:01:20</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:01:30</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:01:40</td>\n",
       "      <td>18.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:01:50</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:02:00</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:02:10</td>\n",
       "      <td>19.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:02:20</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:02:30</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:02:40</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:02:50</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:03:00</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:03:10</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:03:20</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:03:30</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:03:40</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:03:50</td>\n",
       "      <td>17.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:04:00</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:04:10</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:04:20</td>\n",
       "      <td>17.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:04:30</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:04:40</td>\n",
       "      <td>16.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>00:04:50</td>\n",
       "      <td>16.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259170</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:55:00</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259171</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:55:10</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259172</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:55:20</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259173</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:55:30</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259174</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:55:40</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259175</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:55:50</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259176</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:56:00</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259177</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:56:10</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259178</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:56:20</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259179</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:56:30</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259180</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:56:40</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259181</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:56:50</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259182</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:57:00</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259183</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:57:10</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259184</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:57:20</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259185</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:57:30</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259186</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:57:40</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259187</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:57:50</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259188</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:58:00</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259189</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:58:10</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259190</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:58:20</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259191</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:58:30</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259192</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:58:40</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259193</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:58:50</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259194</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:59:00</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259195</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:59:10</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259196</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:59:20</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259197</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:59:30</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259198</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:59:40</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259199</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>23:59:50</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               day      time    p4  Anomaly\n",
       "0       2018-09-01  00:00:00  13.2        0\n",
       "1       2018-09-01  00:00:10  13.2        0\n",
       "2       2018-09-01  00:00:20  13.2        0\n",
       "3       2018-09-01  00:00:30  13.1        0\n",
       "4       2018-09-01  00:00:40  13.1        0\n",
       "5       2018-09-01  00:00:50  13.1        0\n",
       "6       2018-09-01  00:01:00  13.1        0\n",
       "7       2018-09-01  00:01:10  13.0        0\n",
       "8       2018-09-01  00:01:20  13.7        0\n",
       "9       2018-09-01  00:01:30  16.2        0\n",
       "10      2018-09-01  00:01:40  18.7        0\n",
       "11      2018-09-01  00:01:50  19.6        0\n",
       "12      2018-09-01  00:02:00  19.7        0\n",
       "13      2018-09-01  00:02:10  19.8        0\n",
       "14      2018-09-01  00:02:20  19.7        0\n",
       "15      2018-09-01  00:02:30  19.5        0\n",
       "16      2018-09-01  00:02:40  19.3        0\n",
       "17      2018-09-01  00:02:50  19.0        0\n",
       "18      2018-09-01  00:03:00  18.8        0\n",
       "19      2018-09-01  00:03:10  18.6        0\n",
       "20      2018-09-01  00:03:20  18.4        0\n",
       "21      2018-09-01  00:03:30  18.2        0\n",
       "22      2018-09-01  00:03:40  18.0        0\n",
       "23      2018-09-01  00:03:50  17.7        0\n",
       "24      2018-09-01  00:04:00  17.6        0\n",
       "25      2018-09-01  00:04:10  17.4        0\n",
       "26      2018-09-01  00:04:20  17.2        0\n",
       "27      2018-09-01  00:04:30  17.0        0\n",
       "28      2018-09-01  00:04:40  16.9        0\n",
       "29      2018-09-01  00:04:50  16.7        0\n",
       "...            ...       ...   ...      ...\n",
       "259170  2018-09-30  23:55:00  12.3        0\n",
       "259171  2018-09-30  23:55:10  12.3        0\n",
       "259172  2018-09-30  23:55:20  12.3        0\n",
       "259173  2018-09-30  23:55:30  12.3        0\n",
       "259174  2018-09-30  23:55:40  12.3        0\n",
       "259175  2018-09-30  23:55:50  12.3        0\n",
       "259176  2018-09-30  23:56:00  12.3        0\n",
       "259177  2018-09-30  23:56:10  12.3        0\n",
       "259178  2018-09-30  23:56:20  12.3        0\n",
       "259179  2018-09-30  23:56:30  12.3        0\n",
       "259180  2018-09-30  23:56:40  12.3        0\n",
       "259181  2018-09-30  23:56:50  12.3        0\n",
       "259182  2018-09-30  23:57:00  12.3        0\n",
       "259183  2018-09-30  23:57:10  12.3        0\n",
       "259184  2018-09-30  23:57:20  12.3        0\n",
       "259185  2018-09-30  23:57:30  12.3        0\n",
       "259186  2018-09-30  23:57:40  12.3        0\n",
       "259187  2018-09-30  23:57:50  12.3        0\n",
       "259188  2018-09-30  23:58:00  12.3        0\n",
       "259189  2018-09-30  23:58:10  12.3        0\n",
       "259190  2018-09-30  23:58:20  12.3        0\n",
       "259191  2018-09-30  23:58:30  12.3        0\n",
       "259192  2018-09-30  23:58:40  12.3        0\n",
       "259193  2018-09-30  23:58:50  12.3        0\n",
       "259194  2018-09-30  23:59:00  12.3        0\n",
       "259195  2018-09-30  23:59:10  12.3        0\n",
       "259196  2018-09-30  23:59:20  12.3        0\n",
       "259197  2018-09-30  23:59:30  12.3        0\n",
       "259198  2018-09-30  23:59:40  12.3        0\n",
       "259199  2018-09-30  23:59:50  12.3        0\n",
       "\n",
       "[259200 rows x 4 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADAS_env",
   "language": "python",
   "name": "adas_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
