{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "All libraries have been loaded.\n"
     ]
    }
   ],
   "source": [
    "%run ../functions/startup.py\n",
    "random.seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent_dir(directory):\n",
    "    import os\n",
    "    return os.path.dirname(directory)\n",
    "\n",
    "current_dirs_parent = get_parent_dir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = current_dirs_parent\n",
    "folder = 'data_examples/FCS_data/'  # Select data folder\n",
    "name_of_path = 'Labelled_data'\n",
    "\n",
    "\n",
    "path_all = path_base + folder\n",
    "save_path = path_all     # Destination folder to for saving text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_file = \"Labels\"\n",
    "completeName = os.path.join(save_path, name_of_file +\".txt\") \n",
    "\n",
    "path_dir_all = []\n",
    "fold_paths = []\n",
    "for name in os.listdir(path_all):\n",
    "    if os.path.isdir(os.path.join(path_all, name)):\n",
    "        tmp = path_all + name\n",
    "        path_dir_all.append(tmp)\n",
    "        fold_paths.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Post-processing of labels\n",
    "### If combination of folder and file is not unique, take the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_lb = pd.read_csv(completeName, sep=\" \", header=None)\n",
    "data_lb.columns = [\"Path\",\"Anomaly\", \"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data_lb.copy()\n",
    "a = data_lb.duplicated(subset=\"Path\", keep='last')    #Return boolean Series denoting duplicate rows\n",
    "labels = labels[~a]\n",
    "\n",
    "labels = labels.reset_index()\n",
    "labels = labels.drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "name_of_file_1 = \"Labels_postproc\"\n",
    "completeName_1 = os.path.join(save_path, name_of_file_1+\".csv\") \n",
    "\n",
    "labels.to_csv(completeName_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Associating data to labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Randomised = 'No'   \n",
    "Randomised = 'Yes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softsign(x):\n",
    "    out = np.log(np.abs(x)+1)*np.sign(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_file = 'Labels_postproc'\n",
    "completeName = os.path.join(save_path, name_of_file+\".csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "\n",
    "path_dir_all = []\n",
    "fold_paths = []\n",
    "for name in os.listdir(path_all):\n",
    "    if os.path.isdir(os.path.join(path_all, name)):\n",
    "        tmp = path_all + name\n",
    "        path_dir_all.append(tmp)\n",
    "        fold_paths.append(name)\n",
    "\n",
    "fold = []\n",
    "data_fcs = []\n",
    "file_name = []\n",
    "    \n",
    "\n",
    "for path in path_dir_all:       # enter into directories\n",
    "    i=0\n",
    "    file_name_tmp = []\n",
    "    for file in os.listdir(path):        # enter into directory files\n",
    "        if file.endswith(\".fcs\"):\n",
    "            file_name_tmp.append(file)\n",
    "            i += 1\n",
    "            if Randomised == 'No':\n",
    "                file_name_tmp = sorted(file_name_tmp)\n",
    "            elif Randomised == 'Yes':\n",
    "                random.shuffle(file_name_tmp)\n",
    "\n",
    "    for fn in file_name_tmp:\n",
    "        new_path = path + '/' + fn\n",
    "        meta, data = fcsparser.parse(new_path, reformat_meta=True)\n",
    "        data.columns = data.columns.astype(str)\n",
    "        data_fcs.append(data)\n",
    "        file_name.append(fn)\n",
    "    a = [path] * i\n",
    "    fold.extend(a)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr0 = pd.DataFrame(data_fcs[0]).keys()[2]\n",
    "sr1 = pd.DataFrame(data_fcs[0]).keys()[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load anomaly file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_lb = pd.read_csv(completeName, sep=\",\",index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of anomalies: 1.0\n",
      "Labels file size: 29\n"
     ]
    }
   ],
   "source": [
    "# Fraction of anomalies\n",
    "print('Fraction of anomalies:', np.count_nonzero(data_lb['Label'])/len(data_lb))\n",
    "print('Labels file size:', len(data_lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform all anomalies types to 1\n",
    "data_lb_n = data_lb.copy(deep=True)\n",
    "data_lb_n['Label'] = np.where(data_lb['Label']!= 0, 1, data_lb['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape matches data shape: True\n"
     ]
    }
   ],
   "source": [
    "print('Labels shape matches data shape:', data_lb.shape[0]==len(data_fcs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add labels and unique ID for each sample - save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if data_lb.shape[0]==len(data_fcs):\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(data_fcs)):\n",
    "        tmp_df = data_fcs[i].copy(deep=True)\n",
    "        tmp_df.insert(loc=0, column = 'UID', value = i)\n",
    "        tmp_df.insert(loc=tmp_df.shape[1], column = 'Label', value = data_lb['Label'][i])\n",
    "        df = df.append(tmp_df, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save data as pickle\n",
    "\n",
    "file = open(path_base + folder + name_of_path, 'wb')   # open a file, where you want to store the data\n",
    "pickle.dump(df, file, protocol=4)   # dump information to that file\n",
    "file.close()   # close the file\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADAS_env",
   "language": "python",
   "name": "adas_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
