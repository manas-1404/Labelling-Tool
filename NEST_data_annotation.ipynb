{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation tool for time series data\n",
    "\n",
    "By: Stefania Russo, Kris Villez\n",
    "Copyright: 2018, distributed with BSD3 license "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The challenge\n",
    "\n",
    "In the context of the ADASen project, we want to address research questions regarding the utility of supervised and unsupervised machine learning models in anomaly detection for environmental systems. We have therefore selected a range of anomaly detection methods for benchmarking on data sets produced by six infrastructures at Eawag.\n",
    "\n",
    "Critical to the benchmarking is the availability of fully labelled training and test data sets of normal and abnormal behavior in environmental data. \n",
    "An annotation tool has therefore being developed to perform the labelling procedure.\n",
    "\n",
    "This notebook shows an application of the labelling procedure to time series data. Here, each time series is a univariate 24h signal\n",
    "\n",
    "Each series is visualised as a 24h time series.\n",
    "\n",
    "## Current method\n",
    "\n",
    "Below are described the steps for data access, data preparation, visualization and labelling procedure.\n",
    "\n",
    "- The data is in the form of .csv data files. Each data file consists of many 24h sets across 2 sensors.\n",
    "\n",
    "    - if missing values are already replaced with NaNs\n",
    "    - If none, replace missing values with NaNs\n",
    "    - Decide if removing dates with Missing Values\n",
    "    - Perform Annotation\n",
    "\n",
    "- The labelling procedure starts and the first plots are displayed. The plots at the top are univariate sensor signals, where the bottom plot shows a collection of these signals.  \n",
    "\n",
    "- The annotation tool allows the labelling expert to interactivelly select multiple portions of the time series by moving through the data with the mouse cursor.\n",
    "\n",
    "- Each time the button 'Next' is clicked, all the selected areas (time index and sensor value) are saved together with information about the date stamp date. At the end of the procedure, the user can easily access to the anomaly labels in an easy manner.\n",
    "\n",
    "- When the process is over, the plots need to be closed and then the cell 'Save labelled data' hs to be run \n",
    "\n",
    "- Note: if the user wants to change any of his selections, he needs to move forward to the next plot by clicking 'Next', perform a selection of the anomalous data, and then go back and restart.\n",
    "\n",
    "\n",
    "# Usage (general)\n",
    "- Create folder called \"labels\" into your data folder\n",
    "- Select data file name_of_file\n",
    "- Select Case (1 or 2): \n",
    "    - CASE 1 will display 3 plots: the plots at the top are univariate sensor signals, where the bottom plot shows the difference between these signals. \n",
    "    - CASE 2 will display 3 plots: the plots at the top are univariate sensor signals, where the bottom plot shows the signals combined. \n",
    "- Run the cells\n",
    "- After performing the annotation, close the plot and run the last cell 'Save labelled data'\n",
    "- Note: if the user wants to change any of his selections, he needs to move forward to the next plot by clicking 'Next', perform a selection of the anomalous data, and then go back and restart.\n",
    "\n",
    "\n",
    "\n",
    "# Usage as .ipyn script\n",
    "- Run each cell in the notebook\n",
    "- Select data file name_of_file + enter\n",
    "- Select Case + enter\n",
    "- After performing the annotation, close the plot.\n",
    "- Restart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iniziatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries have been loaded.\n"
     ]
    }
   ],
   "source": [
    "# Import Statements\n",
    "%run functions/startup.py\n",
    "random.seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_type = 'ipynb'    #ipynb   #py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_from_terminal = input('Please select Case (1: GAK (p3,p4)  2: Pressure T1 T2 (p1,p2)):  ')\n",
    "text_from_terminal = input(\"Please enter the file name:  \")  # Python 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Case = int(case_from_terminal)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = str(Path.cwd())\n",
    "folder = '/data_examples/NEST_data/'  # Select data folder\n",
    "\n",
    "path_all = path_base + folder\n",
    "save_path = path_all     # Destination folder to for labelled data\n",
    "name_of_file = text_from_terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_file1 = name_of_file + \".csv\"\n",
    "name_of_file_l1 =  'labels/' + name_of_file + '_labels_'\n",
    "name_of_file_l1_time = 'labels/' + name_of_file + '_labels_time'\n",
    "\n",
    "completePath = os.path.join(path_all, name_of_file1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now working with :  /data_examples/NEST_data/  file:  s1\n"
     ]
    }
   ],
   "source": [
    "print ('Now working with : ', folder, ' file: ', name_of_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD zeros and ones with dictionary mapping\n",
    "\n",
    "mapper_dict = {'left_only': 0, 'both': 1}\n",
    "\n",
    "def mp(entry):\n",
    "    \"\"\"\n",
    "    maps new values\n",
    "    \"\"\"\n",
    "    return mapper_dict[entry] if entry in mapper_dict else entry\n",
    "mp = np.vectorize(mp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and basic sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor names: p3 , p4\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(completePath)\n",
    "df.head()\n",
    "df2 = df.copy(deep=True)\n",
    "\n",
    "sr0 = df2.keys()[2]\n",
    "sr1 = df2.keys()[3]\n",
    "print('Sensor names:',sr0,',', sr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day      object\n",
      "hour     object\n",
      "p3      float64\n",
      "p4      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# df2['Datetime'] = df2['day'] + ' ' + df2['hour']\n",
    "# df2['Datetime_'] = [x for x in (pd.to_datetime([i for i in df2['Datetime']], format='%d.%m.%Y %H:%M:%S'))] \n",
    "# df3 = df2.resample('10S', on='Datetime_', base=10).mean()\n",
    "\n",
    "# print(df2)\n",
    "\n",
    "df2['Datetime_'] = pd.to_datetime(df2['day'] + ' ' + df2['hour'], format='%d.%m.%Y %H:%M:%S')\n",
    "df2.set_index('Datetime_', inplace=True)\n",
    "\n",
    "df2.index += pd.Timedelta(seconds=10)\n",
    "\n",
    "# This will round down each timestamp to the nearest 10-second mark\n",
    "df2.index = df2.index - pd.to_timedelta(df2.index.second % 10, unit='s')\n",
    "\n",
    "print(df2.dtypes)\n",
    "\n",
    "df3 = df2[['p3', 'p4']].resample('10S').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.reset_index()\n",
    "df3['day'] = [x.date() for x in df3['Datetime_']] \n",
    "df3['time'] = [x.time() for x in df3['Datetime_']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.copy(deep=True)\n",
    "df4.set_index(['day','time'], inplace=True)\n",
    "\n",
    "df_bf_00 = df4[sr0]\n",
    "df_bf_01 = df4[sr1]\n",
    "df_bf_02 = df4[sr0] - df4[sr1]\n",
    "\n",
    "df4.drop(columns ='Datetime_', inplace=True)\n",
    "df2 = df4.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8640, 8640, 8640, 8640, 8640, 8640]\n",
      "[8640, 8640, 8640, 8640, 8640, 8640]\n",
      "Number of unique dates in date_list: 6\n"
     ]
    }
   ],
   "source": [
    "# Accessing dates\n",
    "i_date = df2.index.get_level_values(0)                                      # get all dates\n",
    "idx_date = np.unique(df2.index.get_level_values(0), return_index=True)[1]      # get index of unique dates\n",
    "date_list = i_date[idx_date]   # get list of all dates\n",
    "\n",
    "# Dates and times\n",
    "data_df2 = df2.copy()\n",
    "\n",
    "data_time = []\n",
    "for pl_i in idx_date:                             # create data_time indeces to have access later\n",
    "    time = data_df2.loc[i_date[pl_i]].index\n",
    "    data_time.append(time)                        # associated to every date segment\n",
    "    \n",
    "time_int = [np.linspace(1, 8640, num = 8640, dtype=int) for _ in range(len(date_list))]\n",
    "\n",
    "# Revised approach to ensure time_int matches the length of actual data for each date\n",
    "# time_int = [np.linspace(1, len(data_df2.loc[date]), num=len(data_df2.loc[date]), dtype=int) for date in date_list]\n",
    "\n",
    "lengths = [len(arr) for arr in time_int]\n",
    "print(lengths)\n",
    "\n",
    "\n",
    "# min_length = min(len(time_int), len(date_list))\n",
    "# time_int, date_list = time_int[:min_length], date_list[:min_length]\n",
    "\n",
    "lengths = [len(arr) for arr in time_int]\n",
    "print(lengths)\n",
    "\n",
    "print(f\"Number of unique dates in date_list: {len(date_list)}\")\n",
    "\n",
    "\n",
    "min_val = min(min(df[df.keys()[2]]),min(df[df.keys()[3]]))\n",
    "max_val = max(max(df[df.keys()[2]]),max(df[df.keys()[3]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8640, 8640, 8640, 8640, 8640, 8640]\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(arr) for arr in time_int]\n",
    "print(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (8640,) and (8639,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m ax4\u001b[38;5;241m.\u001b[39mset_ylim([min_val,max_val])\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pl_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(date_list)): \n\u001b[1;32m---> 46\u001b[0m     \u001b[43max1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_int\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpl_i\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_bf_00\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdate_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpl_i\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m#C0C0C0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     ax2\u001b[38;5;241m.\u001b[39mplot(time_int[pl_i], df_bf_01[date_list[pl_i]]\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#C0C0C0\u001b[39m\u001b[38;5;124m'\u001b[39m, lw\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     49\u001b[0m l, \u001b[38;5;241m=\u001b[39m ax1\u001b[38;5;241m.\u001b[39mplot(time_int[\u001b[38;5;241m0\u001b[39m], df_bf_00[date_list[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#1E90FF\u001b[39m\u001b[38;5;124m'\u001b[39m, lw\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)     \u001b[38;5;66;03m#the first one is the one in blue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lyq09mow\\AppData\\Local\\miniconda3\\envs\\labelENV\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1724\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1721\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1723\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1724\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1725\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1726\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\lyq09mow\\AppData\\Local\\miniconda3\\envs\\labelENV\\Lib\\site-packages\\matplotlib\\axes\\_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lyq09mow\\AppData\\Local\\miniconda3\\envs\\labelENV\\Lib\\site-packages\\matplotlib\\axes\\_base.py:499\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    496\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    500\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    503\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (8640,) and (8639,)"
     ]
    }
   ],
   "source": [
    "#get_ipython().run_line_magic('matplotlib', 'tk')\n",
    "\n",
    "if notebook_type == 'ipynb':\n",
    "    %matplotlib tk\n",
    "\n",
    "if notebook_type == 'py':\n",
    "    import matplotlib as mpl\n",
    "    mpl.use('Qt5Agg')\n",
    "\n",
    "data1 = []\n",
    "data2 = []\n",
    "data123 = []\n",
    "\n",
    "itera = date_list\n",
    "\n",
    "# ########################################\n",
    "# # added\n",
    "\n",
    "# import matplotlib as mpl\n",
    "# mpl.use('Qt5Agg')\n",
    "# #######################################\n",
    "\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "fig = plt.figure()\n",
    "#plt.axis([0, 24, -3, 100])\n",
    "\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0, 0]) # row 0, col 0\n",
    "ax2 = fig.add_subplot(gs[0, 1]) # row 0, col 1\n",
    "ax4 = fig.add_subplot(gs[1, :]) # row 1, span all columns\n",
    "\n",
    "ax1.set_title(sr0, fontdict=None, pad=None)\n",
    "ax2.set_title(sr1, fontdict=None, pad=None)\n",
    "full = sr0 + ' '+ sr1\n",
    "ax4.set_title(full, fontdict=None, pad=None)\n",
    "\n",
    "fig.suptitle(str(date_list[0]), fontsize=12)\n",
    "\n",
    "\n",
    "ax1.set_ylim([min_val,max_val])\n",
    "ax2.set_ylim([min_val,max_val])\n",
    "ax4.set_ylim([min_val,max_val])\n",
    "\n",
    "for pl_i in range(len(date_list)): \n",
    "    ax1.plot(time_int[pl_i], df_bf_00[date_list[pl_i]].values, '#C0C0C0', lw=2)\n",
    "    ax2.plot(time_int[pl_i], df_bf_01[date_list[pl_i]].values, '#C0C0C0', lw=2)\n",
    "    \n",
    "l, = ax1.plot(time_int[0], df_bf_00[date_list[0]].values, '#1E90FF', lw=2)     #the first one is the one in blue\n",
    "l2, = ax2.plot(time_int[0], df_bf_01[date_list[0]].values, '#8B008B')\n",
    "\n",
    "\n",
    "###########################\n",
    "if Case == 1:\n",
    "    ll1, = ax4.plot(time_int[0], df_bf_00[date_list[0]].values, '#C0C0C0')\n",
    "    ll2, = ax4.plot(time_int[0], df_bf_01[date_list[0]].values, '#C0C0C0')\n",
    "    ll3, = ax4.plot(time_int[0], df_bf_02[date_list[0]].values, '#31a354')   # add difference4 plot\n",
    "\n",
    "if Case == 2:\n",
    "    ll1, = ax4.plot(time_int[0], df_bf_00[date_list[0]].values, '#1E90FF')\n",
    "    ll2, = ax4.plot(time_int[0], df_bf_01[date_list[0]].values, '#8B008B')\n",
    "\n",
    "############### Buttons widget  ####################\n",
    "\n",
    "class Index(object):\n",
    "    ind = 0\n",
    "\n",
    "    def next(self, event):\n",
    "        self.ind += 1\n",
    "        i = self.ind % len(itera)\n",
    "\n",
    "        #ydata0 will be the plot alone\n",
    "        ydata1 = df_bf_00[date_list[i]].values   \n",
    "        ydata2 = df_bf_01[date_list[i]].values \n",
    "        ydata3 = df_bf_02[date_list[i]].values \n",
    "        \n",
    "        xdata = time_int[i]          \n",
    "        \n",
    "        l.set_ydata(ydata1)\n",
    "        l.set_xdata(xdata)\n",
    "        l2.set_ydata(ydata2)\n",
    "        l2.set_xdata(xdata)\n",
    "        \n",
    "        if Case == 1:\n",
    "            ll1.set_ydata(ydata1)\n",
    "            ll2.set_ydata(ydata2)\n",
    "            ll3.set_ydata(ydata3)\n",
    "            ll1.set_xdata(xdata) \n",
    "            ll2.set_xdata(xdata)\n",
    "            ll3.set_xdata(xdata)\n",
    "        \n",
    "        if Case == 2:                \n",
    "            ll1.set_ydata(ydata1)\n",
    "            ll2.set_ydata(ydata2)\n",
    "            ll1.set_xdata(xdata) \n",
    "            ll2.set_xdata(xdata)\n",
    "        \n",
    "        \n",
    "        if (i == (0)):\n",
    "            fig.suptitle('End of data files - restarting with data file ' + str(date_list[i]), fontsize=12)\n",
    "        else: \n",
    "            fig.suptitle(str(date_list[i]), fontsize=12)\n",
    "            \n",
    "        plt.draw()\n",
    "\n",
    "    def prev(self, event):\n",
    "        self.ind -= 1\n",
    "        i = self.ind % len(itera)\n",
    "        \n",
    "        #ydata0 will be the plot alone\n",
    "        ydata1 = df_bf_00[date_list[i]].values \n",
    "        ydata2 = df_bf_01[date_list[i]].values \n",
    "        ydata3 = df_bf_02[date_list[i]].values \n",
    "        \n",
    "        xdata = time_int[i]  \n",
    "        \n",
    "        l.set_ydata(ydata1)\n",
    "        l.set_xdata(xdata)\n",
    "        \n",
    "        l2.set_ydata(ydata2)\n",
    "        l2.set_xdata(xdata)\n",
    "        \n",
    "        if Case == 1:\n",
    "            ll1.set_ydata(ydata1)\n",
    "            ll2.set_ydata(ydata2)\n",
    "            ll3.set_ydata(ydata3)\n",
    "            ll1.set_xdata(xdata) \n",
    "            ll2.set_xdata(xdata)\n",
    "            ll3.set_xdata(xdata)\n",
    "        \n",
    "        if Case == 2:                \n",
    "            ll1.set_ydata(ydata1)\n",
    "            ll2.set_ydata(ydata2)\n",
    "            ll1.set_xdata(xdata) \n",
    "            ll2.set_xdata(xdata)\n",
    "        \n",
    "\n",
    "        if (i == (0)):\n",
    "            fig.suptitle('End of data files - restarting with data file ' + str(date_list[i]), fontsize=12)\n",
    "        else: \n",
    "            fig.suptitle(str(date_list[i].date()), fontsize=12)\n",
    "            \n",
    "        plt.draw()\n",
    "\n",
    "callback = Index()\n",
    "\n",
    "axprev = plt.axes([0.7, 0.05, 0.1, 0.075])\n",
    "axnext = plt.axes([0.81, 0.05, 0.1, 0.075])\n",
    "bnext = Button(axnext, 'Next')\n",
    "bnext.on_clicked(callback.next)\n",
    "\n",
    "bprev = Button(axprev, 'Previous')\n",
    "bprev.on_clicked(callback.prev)\n",
    "\n",
    "\"\"\"\n",
    "valore = '11'\n",
    "def presskey(event):\n",
    "    print('Pressed key = ', event.key)\n",
    "    #sys.stdout.flush()    \n",
    "    global valore \n",
    "    valore = event.key       \n",
    "    return valore\n",
    "\"\"\"\n",
    "\n",
    "def onselect1(xmin, xmax):\n",
    "    x = time_int[callback.ind % len(itera)]\n",
    "    y = df_bf_00[date_list[callback.ind % len(itera)]].values \n",
    "    today = date_list[callback.ind % len(itera)]\n",
    "   \n",
    "    indmin1, indmax1 = np.searchsorted(x, (xmin, xmax))\n",
    "    indmax1 = min(len(x) - 1, indmax1)\n",
    "    thisx = x[indmin1:indmax1]\n",
    "    thisy = y[indmin1:indmax1]    \n",
    "    nplist = np.array([today.date() for i in range(len(thisx))])\n",
    "        \n",
    "    a1 = np.c_[nplist, thisx, thisy]\n",
    "    global data1\n",
    "    data1.extend(a1)\n",
    "    #np.savetxt(completeName_label_1, data1)\n",
    "\n",
    "    ax1.axvspan(xmin, xmax, facecolor='red', alpha=0.5)\n",
    "    plt.draw()\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "def onselect2(xmin, xmax):\n",
    "    x = time_int[callback.ind % len(itera)]\n",
    "    y = df_bf_01[date_list[callback.ind % len(itera)]].values \n",
    "    today = date_list[callback.ind % len(itera)]\n",
    "    \n",
    "    indmin, indmax = np.searchsorted(x, (xmin, xmax))\n",
    "    indmax = min(len(x) - 1, indmax)\n",
    "    thisx = x[indmin:indmax]\n",
    "    thisy = y[indmin:indmax]\n",
    "    nplist = np.array([today.date() for i in range(len(thisx))])\n",
    "    \n",
    "    a2 = np.c_[nplist, thisx, thisy]\n",
    "    global data2\n",
    "    data2.extend(a2)\n",
    "\n",
    "    ax2.axvspan(xmin, xmax, facecolor='red', alpha=0.5)\n",
    "    plt.draw()\n",
    "    \n",
    "\n",
    "def onselect4(xmin, xmax):\n",
    "    x = time_int[callback.ind % len(itera)]\n",
    "    y1 = df_bf_00[date_list[callback.ind % len(itera)]].values \n",
    "    y2 = df_bf_01[date_list[callback.ind % len(itera)]].values\n",
    "    today = date_list[callback.ind % len(itera)]\n",
    "    \n",
    "    indmin, indmax = np.searchsorted(x, (xmin, xmax))\n",
    "    indmax = min(len(x) - 1, indmax)\n",
    "    \n",
    "    thisx = x[indmin:indmax]\n",
    "    thisy1 = y1[indmin:indmax]\n",
    "    thisy2 = y2[indmin:indmax]\n",
    "    nplist = np.array([today.date() for i in range(len(thisx))])\n",
    "        \n",
    "    # save\n",
    "    a123 = np.c_[nplist, thisx, thisy1, thisy2]\n",
    "    global data123\n",
    "    data123.extend(a123)\n",
    "\n",
    "    ax4.axvspan(xmin, xmax, facecolor='red', alpha=0.5)\n",
    "    plt.draw()\n",
    "\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "# Connect key event to figure\n",
    "fig.canvas.mpl_connect('key_press_event',presskey)\n",
    "\"\"\"\n",
    "\n",
    "#class1 = Onselect_1()\n",
    "\n",
    "spans1 = SpanSelector(ax1, onselect1, 'horizontal', useblit=False,\n",
    "                      props=dict(alpha=0.5, facecolor='red'))\n",
    "span2 = SpanSelector(ax2, onselect2, 'horizontal', useblit=True,\n",
    "                    props=dict(alpha=0.5, facecolor='red'))\n",
    "span4 = SpanSelector(ax4, onselect4, 'horizontal', useblit=True,\n",
    "                    props=dict(alpha=0.5, facecolor='red'))\n",
    "\n",
    "\n",
    "########################################\n",
    "if notebook_type == 'py':\n",
    "    # added\n",
    "    plt.show()\n",
    "########################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame(data1, columns=['day','time_m', sr0])\n",
    "data2 = pd.DataFrame(data2, columns=['day','time_m', sr1])\n",
    "data123 = pd.DataFrame(data123, columns=['day','time_m', sr0, sr1])\n",
    "\n",
    "# # Raw labels\n",
    "# data1.to_csv(os.path.join(save_path,name_of_file_l1+sr0 + \".csv\") )\n",
    "# data2.to_csv(os.path.join(save_path,name_of_file_l1+sr1 + \".csv\") )\n",
    "# data123.to_csv(os.path.join(save_path,name_of_file_l1+sr0+sr1+ \".csv\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rem_dup(datal):\n",
    "    if (len(datal))==0:\n",
    "        return datal.copy(deep=True)\n",
    "    #list_org = [str(i) for i in datal['day'].values]\n",
    "    list_org = [i for i in datal['day'].values]\n",
    "    states = [list_org[-1]]\n",
    "    index_keep =[True]\n",
    "\n",
    "    for i in range(len(list_org)-2,-1,-1):\n",
    "        if list_org[i]!=list_org[i+1] and list_org[i] not in states:\n",
    "            states.extend([list_org[i]])\n",
    "            index_keep.append(True) \n",
    "\n",
    "        elif list_org[i]!=list_org[i+1] and list_org[i] in states:\n",
    "            index_keep.append(False)\n",
    "\n",
    "        elif list_org[i]==list_org[i+1] and index_keep[len(list_org)-2-i]==False:   # check\n",
    "            index_keep.append(False)\n",
    "\n",
    "        elif list_org[i]==list_org[i+1] and list_org[i] in states:\n",
    "            index_keep.append(True)\n",
    "            \n",
    "    index_keep.reverse()\n",
    "    #index_keep = rem_dup(datal)\n",
    "    datall = datal[index_keep]\n",
    "    return datall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "data1_l = rem_dup(data1)\n",
    "data2_l = rem_dup(data2)\n",
    "data123_l = rem_dup(data123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (6,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m data_df_s2 \u001b[38;5;241m=\u001b[39m data_df\u001b[38;5;241m.\u001b[39mdrop([sr0], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m data_df_s3 \u001b[38;5;241m=\u001b[39m data_df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m----> 7\u001b[0m data_df_s1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_m\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8640\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtime_int\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m data_df_s2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_m\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(time_int, \u001b[38;5;241m8640\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(time_int))\n\u001b[0;32m      9\u001b[0m data_df_s3[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_m\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(time_int, \u001b[38;5;241m8640\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(time_int))\n",
      "File \u001b[1;32mc:\\Users\\lyq09mow\\AppData\\Local\\miniconda3\\envs\\labelENV\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:285\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    202\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lyq09mow\\AppData\\Local\\miniconda3\\envs\\labelENV\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:56\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, method, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\lyq09mow\\AppData\\Local\\miniconda3\\envs\\labelENV\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:45\u001b[0m, in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m     44\u001b[0m     wrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m, method)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu\u001b[38;5;241m.\u001b[39mndarray):\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (6,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "data_df = data_df2.reset_index()\n",
    "\n",
    "data_df_s1 = data_df.drop([sr1], axis=1)\n",
    "data_df_s2 = data_df.drop([sr0], axis=1)\n",
    "data_df_s3 = data_df.copy()\n",
    "\n",
    "data_df_s1['time_m'] = np.reshape(time_int, 8640*len(time_int))\n",
    "data_df_s2['time_m'] = np.reshape(time_int, 8640*len(time_int))\n",
    "data_df_s3['time_m'] = np.reshape(time_int, 8640*len(time_int))\n",
    "\n",
    "data_df_s1['day'] = [x.date() for x in data_df_s1['day']] \n",
    "data_df_s2['day'] = [x.date() for x in data_df_s2['day']] \n",
    "data_df_s3['day'] = [x.date() for x in data_df_s3['day']] \n",
    "\n",
    "data1_l.drop(columns = sr0, inplace=True)\n",
    "data2_l.drop(columns = sr1, inplace=True)\n",
    "data123_l.drop(columns =[sr0, sr1], inplace=True)\n",
    "\n",
    "labels_df_1 = pd.merge(data_df_s1, data1_l, on = ['day', 'time_m'], how='left', indicator=True)\n",
    "labels_df_2 = pd.merge(data_df_s2, data2_l, on = ['day', 'time_m'], how='left', indicator=True)\n",
    "labels_df_123 = pd.merge(data_df_s3, data123_l, on = ['day', 'time_m'], how='left', indicator=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df_1 ['_merge'] = mp(labels_df_1['_merge'])\n",
    "labels_df_2 ['_merge'] = mp(labels_df_2['_merge'])\n",
    "labels_df_123 ['_merge'] = mp(labels_df_123['_merge'])\n",
    "labels_df_1 = labels_df_1.rename(index=str, columns={\"_merge\": \"Anomaly\"})\n",
    "labels_df_2 = labels_df_2.rename(index=str, columns={\"_merge\": \"Anomaly\"})\n",
    "labels_df_123 = labels_df_123.rename(index=str, columns={\"_merge\": \"Anomaly\"})\n",
    "labels_df_1.drop(['time_m'], axis=1, inplace=True)\n",
    "labels_df_2.drop(['time_m'], axis=1, inplace=True)\n",
    "labels_df_123.drop(['time_m'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df_1.to_csv(os.path.join(save_path, name_of_file_l1_time+sr0 + \".csv\") )\n",
    "labels_df_2.to_csv(os.path.join(save_path, name_of_file_l1_time+sr1 + \".csv\") )\n",
    "labels_df_123.to_csv(os.path.join(save_path, name_of_file_l1_time+sr0+sr1 + \".csv\") )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labelENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
